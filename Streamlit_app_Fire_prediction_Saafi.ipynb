{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5f29b989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Invalid value: File does not exist: app.py\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Wn4ziobMWtxD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://saafeai-691595239825.d.codeartifact.eu-west-1.amazonaws.com/pypi/saafe/simple/pyngrok/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pyngrok (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: 401 Error, Credentials not correct for https://saafeai-691595239825.d.codeartifact.eu-west-1.amazonaws.com/pypi/saafe/simple/pip/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pyngrok\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit pyngrok pandas requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eje7A6GJVb3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://saafeai-691595239825.d.codeartifact.eu-west-1.amazonaws.com/pypi/saafe/simple/pyngrok/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pyngrok (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: 401 Error, Credentials not correct for https://saafeai-691595239825.d.codeartifact.eu-west-1.amazonaws.com/pypi/saafe/simple/pip/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pyngrok\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install streamlit pyngrok pandas requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKHmKmNiejky",
    "outputId": "5d257e42-4119-425a-d2c6-5c54b78db688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import time\n",
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(page_title=\"Fire Prediction (3 Models)\", page_icon=\"🔥\", layout=\"wide\")\n",
    "\n",
    "# ---- Endpoints ----\n",
    "M1_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
    "M2_URL = \"https://rnmsxp5s53.us-east-1.awsapprunner.com/predict_features\"\n",
    "M3_URL = \"https://mfyemzf28h.us-east-1.awsapprunner.com/predict\"\n",
    "\n",
    "# ---------- Prefills: Model 1 (Saafe model) ----------\n",
    "M1_NON_FIRE = {\n",
    "  \"frame\": 5678,\n",
    "  \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
    "  \"features\": {\n",
    "    \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
    "    \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
    "    \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
    "    \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
    "    \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
    "    \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
    "    \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
    "    \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
    "    \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
    "    \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
    "    \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
    "    \"spike_count_voc_2m\": 0,\n",
    "    \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
    "    \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
    "    \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
    "    \"is_weekend\": 0, \"asleep_window\": 0,\n",
    "    \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
    "  },\n",
    "  \"decision_threshold\": 0.4\n",
    "}\n",
    "M1_FIRE = {\n",
    "  \"frame\": 1234,\n",
    "  \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
    "  \"features\": {\n",
    "    \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
    "    \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
    "    \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
    "    \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
    "    \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
    "    \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
    "    \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
    "    \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
    "    \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
    "    \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
    "    \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
    "    \"spike_count_voc_2m\": 4,\n",
    "    \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
    "    \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
    "    \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
    "    \"is_weekend\": 0, \"asleep_window\": 1,\n",
    "    \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
    "  },\n",
    "  \"decision_threshold\": 0.4\n",
    "}\n",
    "\n",
    "# ---------- Prefills: Model 2 (18 Features research data) ----------\n",
    "M2_NON_FIRE = {\n",
    "  \"data\": {\n",
    "    \"features_dict\": {\n",
    "      \"t_mean\": 28.0, \"t_std\": 2.0, \"t_max\": 32.0, \"t_p95\": 31.0,\n",
    "      \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.0,\n",
    "      \"t_grad_mean\": 0.5, \"t_grad_std\": 0.2,\n",
    "      \"t_diff_mean\": 0.1, \"t_diff_std\": 0.05,\n",
    "      \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.05,\n",
    "      \"gas_val\": 400.0, \"gas_delta\": 5.0, \"gas_vel\": 0.5,\n",
    "      \"tproxy_val\": 32.0, \"tproxy_delta\": 1.0, \"tproxy_vel\": 0.2\n",
    "    }\n",
    "  },\n",
    "  \"threshold\": 0.5\n",
    "}\n",
    "M2_FIRE = {\n",
    "  \"data\": {\n",
    "    \"features_dict\": {\n",
    "      \"t_mean\": 105.0, \"t_std\": 15.0, \"t_max\": 160.0, \"t_p95\": 150.0,\n",
    "      \"t_hot_area_pct\": 40.0, \"t_hot_largest_blob_pct\": 30.0,\n",
    "      \"t_grad_mean\": 12.0, \"t_grad_std\": 6.0,\n",
    "      \"t_diff_mean\": 8.0, \"t_diff_std\": 4.0,\n",
    "      \"flow_mag_mean\": 5.0, \"flow_mag_std\": 2.0,\n",
    "      \"gas_val\": 2500.0, \"gas_delta\": 600.0, \"gas_vel\": 600.0,\n",
    "      \"tproxy_val\": 160.0, \"tproxy_delta\": 20.0, \"tproxy_vel\": 20.0\n",
    "    }\n",
    "  },\n",
    "  \"threshold\": 0.5\n",
    "}\n",
    "\n",
    "# ---------- Prefills: Model 3 (Kaggle Base model) ----------\n",
    "M3_NON_FIRE = {\n",
    "  \"data\": {\n",
    "    \"Temperature[C]\": 23.5, \"Humidity[%]\": 42, \"TVOC[ppb]\": 3, \"eCO2[ppm]\": 420,\n",
    "    \"PM1.0\": 1.2, \"PM2.5\": 2.3, \"PM10\": 3.4, \"Pressure[hPa]\": 1013.2,\n",
    "    \"Raw H2\": 14500, \"Raw Ethanol\": 21000, \"CNT\": 0, \"UTC\": 0,\n",
    "    \"NC0.5\": 0, \"NC1.0\": 0, \"NC2.5\": 0\n",
    "  }\n",
    "}\n",
    "M3_FIRE = {\n",
    "  \"data\": {\n",
    "    \"Temperature[C]\": 45.7, \"Humidity[%]\": 15.3, \"TVOC[ppb]\": 850, \"eCO2[ppm]\": 2200,\n",
    "    \"PM1.0\": 80.1, \"PM2.5\": 120.5, \"PM10\": 155.0, \"Pressure[hPa]\": 1002.1,\n",
    "    \"Raw H2\": 30000, \"Raw Ethanol\": 42000, \"CNT\": 123456, \"UTC\": 1623859200,\n",
    "    \"NC0.5\": 3500, \"NC1.0\": 2100, \"NC2.5\": 1500\n",
    "  }\n",
    "}\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def coerce_value(v: Any) -> Any:\n",
    "    if isinstance(v, str):\n",
    "        if v.strip() == \"\":\n",
    "            return v\n",
    "        try:\n",
    "            if \".\" in v or \"e\" in v.lower():\n",
    "                return float(v)\n",
    "            return int(v)\n",
    "        except Exception:\n",
    "            return v\n",
    "    return v\n",
    "\n",
    "def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
    "    items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
    "    return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
    "\n",
    "def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    out = {}\n",
    "    for _, row in df.iterrows():\n",
    "        key = str(row.get(\"feature\", \"\")).strip()\n",
    "        if not key:\n",
    "            continue\n",
    "        out[key] = coerce_value(row.get(\"value\"))\n",
    "    return out\n",
    "\n",
    "def post_json(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
    "    r = requests.post(url, json=payload, timeout=timeout_s)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <div style=\"\n",
    "            padding: 12px 14px; border-radius: 8px;\n",
    "            background: {bg}; color: {color}; border: 1px solid {border};\n",
    "            font-weight: 500;\">\n",
    "            {text}\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "def html_summary_table(rows, key_to_color=None):\n",
    "    \"\"\"\n",
    "    rows: List[Tuple[field, value]]\n",
    "    key_to_color: dict like {\"Label\": (\"red\"|\"green\"|\"none\", condition_bool)} is ignored;\n",
    "                  we color based on value semantics below.\n",
    "    \"\"\"\n",
    "    def cell_style(field, val):\n",
    "        # Model 1: Label\n",
    "        if field.lower() == \"label\":\n",
    "            if isinstance(val, str) and val.strip().lower() == \"fire\":\n",
    "                return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
    "            if isinstance(val, str) and val.strip().lower() == \"not fire\":\n",
    "                return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
    "        # Model 2: fire_detected\n",
    "        if field == \"fire_detected\":\n",
    "            if val is True:\n",
    "                return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
    "            if val is False:\n",
    "                return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
    "        # Model 3: fire_prediction\n",
    "        if field == \"fire_prediction\":\n",
    "            if val is True:\n",
    "                return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
    "            if val is False:\n",
    "                return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
    "        return \"\"\n",
    "    html = ['<table style=\"width:100%;border-collapse:collapse;\">']\n",
    "    for field, val in rows:\n",
    "        style = cell_style(field, val)\n",
    "        html.append(\n",
    "            f'<tr>'\n",
    "            f'<td style=\"border:1px solid #ddd;padding:8px;width:35%;font-weight:600;background:#fafafa;\">{field}</td>'\n",
    "            f'<td style=\"border:1px solid #ddd;padding:8px;{style}\">{val}</td>'\n",
    "            f'</tr>'\n",
    "        )\n",
    "    html.append('</table>')\n",
    "    st.markdown(\"\".join(html), unsafe_allow_html=True)\n",
    "\n",
    "# ========================= UI =========================\n",
    "st.title(\"🔥 Fire Prediction — Live data\")\n",
    "tabs = st.tabs([\"Live data fire prediction\", \"18 Features research data\", \"Kaggle Base model\"])\n",
    "\n",
    "# ========================= Model 1 =========================\n",
    "with tabs[0]:\n",
    "    st.subheader(\"Fire prediction live data\")\n",
    "    left, right = st.columns([1, 1])\n",
    "    with left:\n",
    "        m1_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m1_prefill\")\n",
    "    with right:\n",
    "        m1_url = st.text_input(\"Endpoint\", value=M1_URL, key=\"m1_endpoint\")\n",
    "\n",
    "    # Session defaults\n",
    "    if \"m1_frame\" not in st.session_state:\n",
    "        st.session_state.m1_frame = M1_NON_FIRE[\"frame\"]\n",
    "    if \"m1_timestamp\" not in st.session_state:\n",
    "        st.session_state.m1_timestamp = M1_NON_FIRE[\"timestamp\"]\n",
    "    if \"m1_threshold\" not in st.session_state:\n",
    "        st.session_state.m1_threshold = M1_NON_FIRE[\"decision_threshold\"]\n",
    "    if \"m1_table\" not in st.session_state:\n",
    "        st.session_state.m1_table = df_from_features_dict(M1_NON_FIRE[\"features\"])\n",
    "\n",
    "    # Prefill\n",
    "    src1 = M1_NON_FIRE if m1_prefill == \"Non-Fire sample\" else M1_FIRE if m1_prefill == \"Fire sample\" else None\n",
    "    if src1 is not None:\n",
    "        st.session_state.m1_frame = src1[\"frame\"]\n",
    "        st.session_state.m1_timestamp = src1[\"timestamp\"]\n",
    "        st.session_state.m1_threshold = src1.get(\"decision_threshold\", 0.4)\n",
    "        st.session_state.m1_table = df_from_features_dict(src1[\"features\"])\n",
    "\n",
    "    st.markdown(\"**Metadata**\")\n",
    "    c1, c2, c3 = st.columns([1, 1.2, 1])\n",
    "    with c1:\n",
    "        st.session_state.m1_frame = st.number_input(\"frame\", value=int(st.session_state.m1_frame), step=1, key=\"m1_frame_input\")\n",
    "    with c2:\n",
    "        st.session_state.m1_timestamp = st.text_input(\"timestamp (ISO 8601, Zulu)\", value=st.session_state.m1_timestamp, key=\"m1_ts_input\")\n",
    "    with c3:\n",
    "        st.session_state.m1_threshold = st.number_input(\"decision_threshold\", value=float(st.session_state.m1_threshold), step=0.05, format=\"%.4f\", key=\"m1_thr_input\")\n",
    "\n",
    "    st.markdown(\"**Features (editable table)**\")\n",
    "    st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
    "    st.session_state.m1_table = st.data_editor(\n",
    "        st.session_state.m1_table.copy(),\n",
    "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m1_features_editor\"\n",
    "    )\n",
    "\n",
    "    m1_run = st.button(\"Prediction (Saafe model)\", type=\"primary\", use_container_width=True, key=\"m1_run_btn\")\n",
    "    st.divider()\n",
    "\n",
    "    if m1_run:\n",
    "        try:\n",
    "            payload1 = {\n",
    "                \"frame\": int(st.session_state.m1_frame),\n",
    "                \"timestamp\": st.session_state.m1_timestamp,\n",
    "                \"features\": features_dict_from_df(st.session_state.m1_table),\n",
    "                \"decision_threshold\": float(st.session_state.m1_threshold),\n",
    "            }\n",
    "            with st.spinner(\"Calling AWS Lambda...\"):\n",
    "                t0 = time.time()\n",
    "                resp1 = post_json(m1_url, payload1, timeout_s=25.0)\n",
    "                elapsed = time.time() - t0\n",
    "\n",
    "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
    "\n",
    "            # Colored banner + summary table (Label cell colored)\n",
    "            pred = resp1.get(\"prediction\", {}) or {}\n",
    "            lbl = str(pred.get(\"label\", \"\")).lower()\n",
    "            if \"fire\" in lbl and \"not\" not in lbl:\n",
    "                colored_box(\"🔥 Fire detected by Saafe model\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
    "            else:\n",
    "                colored_box(\"✅ Not Fire (Saafe model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
    "\n",
    "            st.subheader(\"Prediction Summary\")\n",
    "            summary_rows = [\n",
    "                (\"Label\", str(pred.get(\"label\", \"—\"))),\n",
    "                (\"Fire probability\", f\"{pred.get('fire_probability'):.6f}\" if isinstance(pred.get(\"fire_probability\"), (int, float)) else str(pred.get(\"fire_probability\"))),\n",
    "                (\"Frame\", resp1.get(\"frame\", payload1[\"frame\"])),\n",
    "                (\"Timestamp\", resp1.get(\"timestamp\", payload1[\"timestamp\"])),\n",
    "            ]\n",
    "            html_summary_table(summary_rows)\n",
    "\n",
    "            # Explanation tables — Local first, then Global\n",
    "            expl = resp1.get(\"explanation\", {}) or {}\n",
    "            lcontrib = expl.get(\"local_contributions\", [])\n",
    "            gtf = expl.get(\"global_top_features\", [])\n",
    "\n",
    "            if isinstance(lcontrib, list) and lcontrib:\n",
    "                st.subheader(\"Local Contributions\")\n",
    "                st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
    "\n",
    "            if isinstance(gtf, list) and gtf:\n",
    "                st.subheader(\"Global Top Features\")\n",
    "                st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
    "\n",
    "            notes = expl.get(\"notes\")\n",
    "            if notes:\n",
    "                colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
    "\n",
    "        except requests.HTTPError as e:\n",
    "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {e}\")\n",
    "\n",
    "# ========================= Model 2 =========================\n",
    "with tabs[1]:\n",
    "    st.subheader(\"18 Features research data\")\n",
    "    left, right = st.columns([1, 1])\n",
    "    with left:\n",
    "        m2_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m2_prefill\")\n",
    "    with right:\n",
    "        m2_url = st.text_input(\"Endpoint\", value=M2_URL, key=\"m2_endpoint\")\n",
    "\n",
    "    if \"m2_threshold\" not in st.session_state:\n",
    "        st.session_state.m2_threshold = float(M2_NON_FIRE[\"threshold\"])\n",
    "    if \"m2_table\" not in st.session_state:\n",
    "        st.session_state.m2_table = df_from_features_dict(M2_NON_FIRE[\"data\"][\"features_dict\"])\n",
    "\n",
    "    src2 = M2_NON_FIRE if m2_prefill == \"Non-Fire sample\" else M2_FIRE if m2_prefill == \"Fire sample\" else None\n",
    "    if src2 is not None:\n",
    "        st.session_state.m2_threshold = float(src2.get(\"threshold\", 0.5))\n",
    "        st.session_state.m2_table = df_from_features_dict(src2[\"data\"][\"features_dict\"])\n",
    "\n",
    "    st.markdown(\"**Threshold**\")\n",
    "    st.session_state.m2_threshold = st.number_input(\"threshold\", value=float(st.session_state.m2_threshold), step=0.05, format=\"%.2f\", key=\"m2_thr_input\")\n",
    "\n",
    "    st.markdown(\"**Features (editable table)**\")\n",
    "    st.caption(\"Exactly 18 core features expected by this API.\")\n",
    "    st.session_state.m2_table = st.data_editor(\n",
    "        st.session_state.m2_table.copy(),\n",
    "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m2_features_editor\"\n",
    "    )\n",
    "\n",
    "    m2_run = st.button(\"Prediction (18 Features)\", type=\"primary\", use_container_width=True, key=\"m2_run_btn\")\n",
    "    st.divider()\n",
    "\n",
    "    if m2_run:\n",
    "        try:\n",
    "            payload2 = {\n",
    "                \"data\": {\"features_dict\": features_dict_from_df(st.session_state.m2_table)},\n",
    "                \"threshold\": float(st.session_state.m2_threshold),\n",
    "            }\n",
    "            with st.spinner(\"Calling 18-Features API...\"):\n",
    "                t0 = time.time()\n",
    "                resp2 = post_json(m2_url, payload2, timeout_s=25.0)\n",
    "                elapsed = time.time() - t0\n",
    "\n",
    "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
    "\n",
    "            # Banner FIRST (as requested)\n",
    "            if bool(resp2.get(\"fire_detected\", False)):\n",
    "                colored_box(\"🔥 Fire detected (18 Features)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
    "            else:\n",
    "                colored_box(\"✅ Not Fire (18 Features)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
    "\n",
    "            # Summary table with colored fire_detected cell\n",
    "            st.subheader(\"Prediction Summary\")\n",
    "            rows = [\n",
    "                (\"fire_detected\", bool(resp2.get(\"fire_detected\", False))),\n",
    "                (\"score\", f\"{resp2.get('score'):.6f}\" if isinstance(resp2.get(\"score\"), (int, float)) else str(resp2.get(\"score\"))),\n",
    "                (\"latency_ms\", f\"{resp2.get('latency_ms'):.3f}\" if isinstance(resp2.get(\"latency_ms\"), (int, float)) else str(resp2.get(\"latency_ms\"))),\n",
    "            ]\n",
    "            html_summary_table(rows)\n",
    "\n",
    "        except requests.HTTPError as e:\n",
    "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {e}\")\n",
    "\n",
    "# ========================= Model 3 =========================\n",
    "with tabs[2]:\n",
    "    st.subheader(\"Kaggle Base model\")\n",
    "    left, right = st.columns([1, 1])\n",
    "    with left:\n",
    "        m3_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m3_prefill\")\n",
    "    with right:\n",
    "        m3_url = st.text_input(\"Endpoint\", value=M3_URL, key=\"m3_endpoint\")\n",
    "\n",
    "    if \"m3_table\" not in st.session_state:\n",
    "        st.session_state.m3_table = df_from_features_dict(M3_NON_FIRE[\"data\"])\n",
    "\n",
    "    # Prefill\n",
    "    src3 = M3_NON_FIRE if m3_prefill == \"Non-Fire sample\" else M3_FIRE if m3_prefill == \"Fire sample\" else None\n",
    "    if src3 is not None:\n",
    "        st.session_state.m3_table = df_from_features_dict(src3[\"data\"])\n",
    "\n",
    "    st.markdown(\"**Features (editable table)**\")\n",
    "    st.caption(\"Kaggle Base model sensor set.\")\n",
    "    st.session_state.m3_table = st.data_editor(\n",
    "        st.session_state.m3_table.copy(),\n",
    "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m3_features_editor\"\n",
    "    )\n",
    "\n",
    "    m3_run = st.button(\"Prediction (Kaggle Base)\", type=\"primary\", use_container_width=True, key=\"m3_run_btn\")\n",
    "    st.divider()\n",
    "\n",
    "    if m3_run:\n",
    "        try:\n",
    "            payload3 = {\"data\": features_dict_from_df(st.session_state.m3_table)}\n",
    "            with st.spinner(\"Calling Kaggle Base API...\"):\n",
    "                t0 = time.time()\n",
    "                resp3 = post_json(m3_url, payload3, timeout_s=25.0)\n",
    "                elapsed = time.time() - t0\n",
    "\n",
    "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
    "\n",
    "            # Banner FIRST (as requested)\n",
    "            if bool(resp3.get(\"fire_prediction\", False)):\n",
    "                colored_box(\"🔥 Fire detected (Kaggle Base model)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
    "            else:\n",
    "                colored_box(\"✅ Not Fire (Kaggle Base model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
    "\n",
    "            # Summary table with colored fire_prediction cell\n",
    "            st.subheader(\"Prediction Summary\")\n",
    "            rows = [\n",
    "                (\"fire_prediction\", bool(resp3.get(\"fire_prediction\", False))),\n",
    "                (\"score\", f\"{resp3.get('score'):.12f}\" if isinstance(resp3.get(\"score\"), (int, float)) else str(resp3.get(\"score\"))),\n",
    "                (\"latency_ms\", f\"{resp3.get('latency_ms'):.3f}\" if isinstance(resp3.get(\"latency_ms\"), (int, float)) else str(resp3.get(\"latency_ms\"))),\n",
    "            ]\n",
    "            html_summary_table(rows)\n",
    "\n",
    "        except requests.HTTPError as e:\n",
    "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lr3XGxdQVyg-",
    "outputId": "7976b7ba-c734-404a-9f85-f976657c1dad"
   },
   "outputs": [],
   "source": [
    "# Kill any previous processes (ignore errors if none)\n",
    "!pkill -f streamlit || true\n",
    "!pkill -f ngrok || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OdVn6kfX7Qi",
    "outputId": "be095ad5-6516-49fa-e26f-b2fd34d5411a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyngrok'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msocket\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msubprocess\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtextwrap\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyngrok\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ngrok\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ----- your ngrok token -----\u001b[39;00m\n\u001b[32m      5\u001b[39m NGROK_TOKEN = \u001b[33m\"\u001b[39m\u001b[33m2xmWjT1LoIIVYxxXxDBeHpYaOZz_3Z9VdDRCJvjMvsRGdbzGZ\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyngrok'"
     ]
    }
   ],
   "source": [
    "import os, socket, subprocess, time, textwrap\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# ----- your ngrok token -----\n",
    "NGROK_TOKEN = \"2xmWjT1LoIIVYxxXxDBeHpYaOZz_3Z9VdDRCJvjMvsRGdbzGZ\"\n",
    "\n",
    "# Ensure app.py exists; if not, stop here\n",
    "assert os.path.exists(\"app.py\"), \"app.py not found. Make sure you saved the Streamlit app.\"\n",
    "\n",
    "# Find a free port starting at 8501\n",
    "def get_free_port(start=8501, tries=30):\n",
    "    for p in range(start, start+tries):\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            try:\n",
    "                s.bind((\"\", p))\n",
    "                return p\n",
    "            except OSError:\n",
    "                continue\n",
    "    raise RuntimeError(\"No free port found\")\n",
    "\n",
    "port = get_free_port()\n",
    "\n",
    "# Start Streamlit in background and log to file\n",
    "logfile = \"/tmp/streamlit.log\"\n",
    "if os.path.exists(logfile):\n",
    "    os.remove(logfile)\n",
    "\n",
    "proc = subprocess.Popen(\n",
    "    [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"0.0.0.0\", \"--server.port\", str(port)],\n",
    "    stdout=open(logfile, \"w\"), stderr=subprocess.STDOUT, env=os.environ.copy()\n",
    ")\n",
    "\n",
    "# Wait a bit for Streamlit to boot\n",
    "time.sleep(4)\n",
    "\n",
    "# Show the last lines of the log (useful if there's an error)\n",
    "print(\"---- Streamlit log (tail) ----\")\n",
    "if os.path.exists(logfile):\n",
    "    print(textwrap.indent(\"\".join(open(logfile).read().splitlines(True)[-60:]), \"  \"))\n",
    "else:\n",
    "    print(\"  (no log yet)\")\n",
    "\n",
    "# Start a fresh ngrok agent and open ONE tunnel\n",
    "ngrok.kill()\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "public_url = ngrok.connect(port)\n",
    "print(\"\\n🌍 Public URL:\", public_url)\n",
    "print(f\"⚙️  Internal target: http://localhost:{port}\")\n",
    "print(\"\\nOpen the 🌍 Public URL in your browser (NOT localhost).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhVrf-sSYczq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc69MVXleeXu"
   },
   "source": [
    " 2 Model testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUNiUWtMbS7e",
    "outputId": "3d5e0513-966e-418b-9590-6d7580750888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile app.py\n",
    "# import time\n",
    "# from typing import Any, Dict\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import streamlit as st\n",
    "\n",
    "# st.set_page_config(page_title=\"Fire Prediction (2 Models)\", page_icon=\"🔥\", layout=\"wide\")\n",
    "\n",
    "# # ---- Endpoints ----\n",
    "# LAMBDA_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
    "# APP_RUNNER_URL = \"https://rnmsxp5s53.us-east-1.awsapprunner.com/predict_features\"\n",
    "\n",
    "# # ---------- Samples: Model 1 (Full model, many features) ----------\n",
    "# M1_NON_FIRE = {\n",
    "#   \"frame\": 5678,\n",
    "#   \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
    "#   \"features\": {\n",
    "#     \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
    "#     \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
    "#     \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
    "#     \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
    "#     \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
    "\n",
    "#     \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
    "#     \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
    "#     \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
    "#     \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
    "\n",
    "#     \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
    "#     \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
    "#     \"spike_count_voc_2m\": 0,\n",
    "\n",
    "#     \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
    "#     \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
    "#     \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
    "\n",
    "#     \"is_weekend\": 0, \"asleep_window\": 0,\n",
    "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
    "#   },\n",
    "#   \"decision_threshold\": 0.4\n",
    "# }\n",
    "\n",
    "# M1_FIRE = {\n",
    "#   \"frame\": 1234,\n",
    "#   \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
    "#   \"features\": {\n",
    "#     \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
    "#     \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
    "#     \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
    "#     \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
    "#     \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
    "#     \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
    "#     \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
    "#     \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
    "#     \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
    "#     \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
    "#     \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
    "#     \"spike_count_voc_2m\": 4,\n",
    "#     \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
    "#     \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
    "#     \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
    "#     \"is_weekend\": 0, \"asleep_window\": 1,\n",
    "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
    "#   },\n",
    "#   \"decision_threshold\": 0.4\n",
    "# }\n",
    "\n",
    "# # ---------- Samples: Model 2 (18 Features research data) ----------\n",
    "# M2_NON_FIRE = {\n",
    "#   \"data\": {\n",
    "#     \"features_dict\": {\n",
    "#       \"t_mean\": 28.0, \"t_std\": 2.0, \"t_max\": 32.0, \"t_p95\": 31.0,\n",
    "#       \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.0,\n",
    "#       \"t_grad_mean\": 0.5, \"t_grad_std\": 0.2,\n",
    "#       \"t_diff_mean\": 0.1, \"t_diff_std\": 0.05,\n",
    "#       \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.05,\n",
    "#       \"gas_val\": 400.0, \"gas_delta\": 5.0, \"gas_vel\": 0.5,\n",
    "#       \"tproxy_val\": 32.0, \"tproxy_delta\": 1.0, \"tproxy_vel\": 0.2\n",
    "#     }\n",
    "#   },\n",
    "#   \"threshold\": 0.5\n",
    "# }\n",
    "\n",
    "# M2_FIRE = {\n",
    "#   \"data\": {\n",
    "#     \"features_dict\": {\n",
    "#       \"t_mean\": 105.0, \"t_std\": 15.0, \"t_max\": 160.0, \"t_p95\": 150.0,\n",
    "#       \"t_hot_area_pct\": 40.0, \"t_hot_largest_blob_pct\": 30.0,\n",
    "#       \"t_grad_mean\": 12.0, \"t_grad_std\": 6.0,\n",
    "#       \"t_diff_mean\": 8.0, \"t_diff_std\": 4.0,\n",
    "#       \"flow_mag_mean\": 5.0, \"flow_mag_std\": 2.0,\n",
    "#       \"gas_val\": 2500.0, \"gas_delta\": 600.0, \"gas_vel\": 600.0,\n",
    "#       \"tproxy_val\": 160.0, \"tproxy_delta\": 20.0, \"tproxy_vel\": 20.0\n",
    "#     }\n",
    "#   },\n",
    "#   \"threshold\": 0.5\n",
    "# }\n",
    "\n",
    "# # ---------- Helpers ----------\n",
    "# def coerce_value(v: Any) -> Any:\n",
    "#     if isinstance(v, str):\n",
    "#         if v.strip() == \"\":\n",
    "#             return v\n",
    "#         try:\n",
    "#             if \".\" in v or \"e\" in v.lower():\n",
    "#                 return float(v)\n",
    "#             return int(v)\n",
    "#         except Exception:\n",
    "#             return v\n",
    "#     return v\n",
    "\n",
    "# def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
    "#     items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
    "#     return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
    "\n",
    "# def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "#     out = {}\n",
    "#     for _, row in df.iterrows():\n",
    "#         key = str(row.get(\"feature\", \"\")).strip()\n",
    "#         if not key:\n",
    "#             continue\n",
    "#         out[key] = coerce_value(row.get(\"value\"))\n",
    "#     return out\n",
    "\n",
    "# def post_json(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
    "#     r = requests.post(url, json=payload, timeout=timeout_s)\n",
    "#     r.raise_for_status()\n",
    "#     return r.json()\n",
    "\n",
    "# def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
    "#     st.markdown(\n",
    "#         f\"\"\"\n",
    "#         <div style=\"\n",
    "#             padding: 12px 14px;\n",
    "#             border-radius: 8px;\n",
    "#             background: {bg};\n",
    "#             color: {color};\n",
    "#             border: 1px solid {border};\n",
    "#             font-weight: 500;\">\n",
    "#             {text}\n",
    "#         </div>\n",
    "#         \"\"\",\n",
    "#         unsafe_allow_html=True\n",
    "#     )\n",
    "\n",
    "# # ========================= UI =========================\n",
    "# st.title(\"🔥 Fire Prediction — Table Only (Two Models)\")\n",
    "# tabs = st.tabs([\"Full model (AWS Lambda)\", \"18 Features research data\"])\n",
    "\n",
    "# # ========================= Model 1 =========================\n",
    "# with tabs[0]:\n",
    "#     st.subheader(\"Full model (AWS Lambda)\")\n",
    "#     left, right = st.columns([1, 1])\n",
    "#     with left:\n",
    "#         m1_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m1_prefill\")\n",
    "#     with right:\n",
    "#         lambda_url = st.text_input(\"Endpoint\", value=LAMBDA_URL, key=\"m1_endpoint\")\n",
    "\n",
    "#     # Session defaults for Model 1\n",
    "#     if \"m1_frame\" not in st.session_state:\n",
    "#         st.session_state.m1_frame = M1_NON_FIRE[\"frame\"]\n",
    "#     if \"m1_timestamp\" not in st.session_state:\n",
    "#         st.session_state.m1_timestamp = M1_NON_FIRE[\"timestamp\"]\n",
    "#     if \"m1_threshold\" not in st.session_state:\n",
    "#         st.session_state.m1_threshold = M1_NON_FIRE[\"decision_threshold\"]\n",
    "#     if \"m1_table\" not in st.session_state:\n",
    "#         st.session_state.m1_table = df_from_features_dict(M1_NON_FIRE[\"features\"])\n",
    "\n",
    "#     # Apply prefill\n",
    "#     src1 = M1_NON_FIRE if m1_prefill == \"Non-Fire sample\" else M1_FIRE if m1_prefill == \"Fire sample\" else None\n",
    "#     if src1 is not None:\n",
    "#         st.session_state.m1_frame = src1[\"frame\"]\n",
    "#         st.session_state.m1_timestamp = src1[\"timestamp\"]\n",
    "#         st.session_state.m1_threshold = src1.get(\"decision_threshold\", 0.4)\n",
    "#         st.session_state.m1_table = df_from_features_dict(src1[\"features\"])\n",
    "\n",
    "#     st.markdown(\"**Metadata**\")\n",
    "#     c1, c2, c3 = st.columns([1, 1.2, 1])\n",
    "#     with c1:\n",
    "#         st.session_state.m1_frame = st.number_input(\"frame\", value=int(st.session_state.m1_frame), step=1, key=\"m1_frame_input\")\n",
    "#     with c2:\n",
    "#         st.session_state.m1_timestamp = st.text_input(\"timestamp (ISO 8601, Zulu)\", value=st.session_state.m1_timestamp, key=\"m1_ts_input\")\n",
    "#     with c3:\n",
    "#         st.session_state.m1_threshold = st.number_input(\"decision_threshold\", value=float(st.session_state.m1_threshold), step=0.05, format=\"%.4f\", key=\"m1_thr_input\")\n",
    "\n",
    "#     st.markdown(\"**Features (editable table)**\")\n",
    "#     st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
    "#     st.session_state.m1_table = st.data_editor(\n",
    "#         st.session_state.m1_table.copy(),\n",
    "#         num_rows=\"dynamic\",\n",
    "#         use_container_width=True,\n",
    "#         hide_index=True,\n",
    "#         key=\"m1_features_editor\"\n",
    "#     )\n",
    "\n",
    "#     m1_run = st.button(\"Prediction (Full model)\", type=\"primary\", use_container_width=True, key=\"m1_run_btn\")\n",
    "#     st.divider()\n",
    "\n",
    "#     if m1_run:\n",
    "#         try:\n",
    "#             payload1 = {\n",
    "#                 \"frame\": int(st.session_state.m1_frame),\n",
    "#                 \"timestamp\": st.session_state.m1_timestamp,\n",
    "#                 \"features\": features_dict_from_df(st.session_state.m1_table),\n",
    "#                 \"decision_threshold\": float(st.session_state.m1_threshold),\n",
    "#             }\n",
    "#             with st.spinner(\"Calling AWS Lambda...\"):\n",
    "#                 t0 = time.time()\n",
    "#                 resp1 = post_json(lambda_url, payload1, timeout_s=25.0)\n",
    "#                 elapsed = time.time() - t0\n",
    "\n",
    "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
    "\n",
    "#             # Build a small summary table (no raw JSON)\n",
    "#             pred = resp1.get(\"prediction\", {}) or {}\n",
    "#             summary_rows = [\n",
    "#                 [\"Label\", str(pred.get(\"label\", \"—\"))],\n",
    "#                 [\"Fire probability\", f\"{pred.get('fire_probability'):.6f}\" if isinstance(pred.get(\"fire_probability\"), (int, float)) else str(pred.get(\"fire_probability\"))],\n",
    "#                 [\"Frame\", resp1.get(\"frame\", payload1[\"frame\"])],\n",
    "#                 [\"Timestamp\", resp1.get(\"timestamp\", payload1[\"timestamp\"])],\n",
    "#             ]\n",
    "#             st.subheader(\"Prediction Summary\")\n",
    "#             st.dataframe(pd.DataFrame(summary_rows, columns=[\"Field\", \"Value\"]), use_container_width=True)\n",
    "\n",
    "#             # Colored banner\n",
    "#             lbl = str(pred.get(\"label\", \"\")).lower()\n",
    "#             if \"fire\" in lbl and \"not\" not in lbl:\n",
    "#                 colored_box(\"🔥 Fire detected by Full model\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
    "#             else:\n",
    "#                 colored_box(\"✅ Not Fire (Full model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
    "\n",
    "#             # Explanation tables (Local first, then Global)\n",
    "#             expl = resp1.get(\"explanation\", {}) or {}\n",
    "#             lcontrib = expl.get(\"local_contributions\", [])\n",
    "#             gtf = expl.get(\"global_top_features\", [])\n",
    "\n",
    "#             if isinstance(lcontrib, list) and lcontrib:\n",
    "#                 st.subheader(\"Local Contributions\")\n",
    "#                 st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
    "\n",
    "#             if isinstance(gtf, list) and gtf:\n",
    "#                 st.subheader(\"Global Top Features\")\n",
    "#                 st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
    "\n",
    "#             notes = expl.get(\"notes\")\n",
    "#             if notes:\n",
    "#                 colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
    "\n",
    "#         except requests.HTTPError as e:\n",
    "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
    "#         except Exception as e:\n",
    "#             st.error(f\"Error: {e}\")\n",
    "\n",
    "# # ========================= Model 2 =========================\n",
    "# with tabs[1]:\n",
    "#     st.subheader(\"18 Features research data\")\n",
    "#     left, right = st.columns([1, 1])\n",
    "#     with left:\n",
    "#         m2_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m2_prefill\")\n",
    "#     with right:\n",
    "#         app_runner_url = st.text_input(\"Endpoint\", value=APP_RUNNER_URL, key=\"m2_endpoint\")\n",
    "\n",
    "#     # Session defaults for Model 2\n",
    "#     if \"m2_threshold\" not in st.session_state:\n",
    "#         st.session_state.m2_threshold = float(M2_NON_FIRE[\"threshold\"])\n",
    "#     if \"m2_table\" not in st.session_state:\n",
    "#         st.session_state.m2_table = df_from_features_dict(M2_NON_FIRE[\"data\"][\"features_dict\"])\n",
    "\n",
    "#     # Apply prefill\n",
    "#     src2 = M2_NON_FIRE if m2_prefill == \"Non-Fire sample\" else M2_FIRE if m2_prefill == \"Fire sample\" else None\n",
    "#     if src2 is not None:\n",
    "#         st.session_state.m2_threshold = float(src2.get(\"threshold\", 0.5))\n",
    "#         st.session_state.m2_table = df_from_features_dict(src2[\"data\"][\"features_dict\"])\n",
    "\n",
    "#     st.markdown(\"**Threshold**\")\n",
    "#     st.session_state.m2_threshold = st.number_input(\"threshold\", value=float(st.session_state.m2_threshold), step=0.05, format=\"%.2f\", key=\"m2_thr_input\")\n",
    "\n",
    "#     st.markdown(\"**Features (editable table)**\")\n",
    "#     st.caption(\"Exactly 18 core features expected in this research API. You can edit values below.\")\n",
    "#     st.session_state.m2_table = st.data_editor(\n",
    "#         st.session_state.m2_table.copy(),\n",
    "#         num_rows=\"dynamic\",\n",
    "#         use_container_width=True,\n",
    "#         hide_index=True,\n",
    "#         key=\"m2_features_editor\"\n",
    "#     )\n",
    "\n",
    "#     m2_run = st.button(\"Prediction (18 Features)\", type=\"primary\", use_container_width=True, key=\"m2_run_btn\")\n",
    "#     st.divider()\n",
    "\n",
    "#     if m2_run:\n",
    "#         try:\n",
    "#             payload2 = {\n",
    "#                 \"data\": {\"features_dict\": features_dict_from_df(st.session_state.m2_table)},\n",
    "#                 \"threshold\": float(st.session_state.m2_threshold),\n",
    "#             }\n",
    "#             with st.spinner(\"Calling 18-Features API...\"):\n",
    "#                 t0 = time.time()\n",
    "#                 resp2 = post_json(app_runner_url, payload2, timeout_s=25.0)\n",
    "#                 elapsed = time.time() - t0\n",
    "\n",
    "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
    "\n",
    "#             # Expecting: {\"fire_detected\": bool, \"score\": float, \"latency_ms\": float}\n",
    "#             # Render strictly as a table (no raw JSON)\n",
    "#             rows = [\n",
    "#                 [\"fire_detected\", resp2.get(\"fire_detected\", \"—\")],\n",
    "#                 [\"score\", f\"{resp2.get('score'):.6f}\" if isinstance(resp2.get(\"score\"), (int, float)) else str(resp2.get(\"score\"))],\n",
    "#                 [\"latency_ms\", f\"{resp2.get('latency_ms'):.3f}\" if isinstance(resp2.get(\"latency_ms\"), (int, float)) else str(resp2.get(\"latency_ms\"))],\n",
    "#             ]\n",
    "#             st.subheader(\"Prediction Summary\")\n",
    "#             st.dataframe(pd.DataFrame(rows, columns=[\"Field\", \"Value\"]), use_container_width=True)\n",
    "\n",
    "#             # Colored banner\n",
    "#             if bool(resp2.get(\"fire_detected\", False)):\n",
    "#                 colored_box(\"🔥 Fire detected (18 Features)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
    "#             else:\n",
    "#                 colored_box(\"✅ Not Fire (18 Features)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
    "\n",
    "#         except requests.HTTPError as e:\n",
    "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
    "#         except Exception as e:\n",
    "#             st.error(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKYRiUrobIds"
   },
   "source": [
    "Live data app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEdFX5viVqgI",
    "outputId": "fed275e9-922a-42b7-9881-5577a2a55fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile app.py\n",
    "# import json\n",
    "# import time\n",
    "# from typing import Any, Dict\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import streamlit as st\n",
    "\n",
    "# st.set_page_config(page_title=\"Fire Prediction (Live data)\", page_icon=\"🔥\", layout=\"wide\")\n",
    "\n",
    "# DEFAULT_LAMBDA_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
    "\n",
    "# # ---------- Samples ----------\n",
    "# NON_FIRE_SAMPLE = {\n",
    "#   \"frame\": 5678,\n",
    "#   \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
    "#   \"features\": {\n",
    "#     \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
    "#     \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
    "#     \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
    "#     \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
    "#     \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
    "\n",
    "#     \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
    "#     \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
    "#     \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
    "#     \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
    "\n",
    "#     \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
    "#     \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
    "#     \"spike_count_voc_2m\": 0,\n",
    "\n",
    "#     \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
    "#     \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
    "#     \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
    "\n",
    "#     \"is_weekend\": 0, \"asleep_window\": 0,\n",
    "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
    "#   },\n",
    "#   \"decision_threshold\": 0.4\n",
    "# }\n",
    "\n",
    "# FIRE_SAMPLE = {\n",
    "#   \"frame\": 1234,\n",
    "#   \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
    "#   \"features\": {\n",
    "#     \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
    "#     \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
    "#     \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
    "#     \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
    "#     \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
    "#     \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
    "#     \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
    "#     \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
    "#     \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
    "#     \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
    "#     \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
    "#     \"spike_count_voc_2m\": 4,\n",
    "#     \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
    "#     \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
    "#     \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
    "#     \"is_weekend\": 0, \"asleep_window\": 1,\n",
    "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
    "#   },\n",
    "#   \"decision_threshold\": 0.4\n",
    "# }\n",
    "\n",
    "# # ---------- Helpers ----------\n",
    "# def coerce_value(v: Any) -> Any:\n",
    "#     if isinstance(v, str):\n",
    "#         if v.strip() == \"\":\n",
    "#             return v\n",
    "#         try:\n",
    "#             if \".\" in v or \"e\" in v.lower():\n",
    "#                 return float(v)\n",
    "#             return int(v)\n",
    "#         except Exception:\n",
    "#             return v\n",
    "#     return v\n",
    "\n",
    "# def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "#     out = {}\n",
    "#     for _, row in df.iterrows():\n",
    "#         key = str(row.get(\"feature\", \"\")).strip()\n",
    "#         if not key:\n",
    "#             continue\n",
    "#         out[key] = coerce_value(row.get(\"value\"))\n",
    "#     return out\n",
    "\n",
    "# def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
    "#     items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
    "#     return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
    "\n",
    "# def call_lambda(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     r = requests.post(url, headers=headers, json=payload, timeout=timeout_s)\n",
    "#     r.raise_for_status()\n",
    "#     return r.json()\n",
    "\n",
    "# def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
    "#     st.markdown(\n",
    "#         f\"\"\"\n",
    "#         <div style=\"\n",
    "#             padding: 12px 14px;\n",
    "#             border-radius: 8px;\n",
    "#             background: {bg};\n",
    "#             color: {color};\n",
    "#             border: 1px solid {border};\n",
    "#             font-weight: 500;\">\n",
    "#             {text}\n",
    "#         </div>\n",
    "#         \"\"\",\n",
    "#         unsafe_allow_html=True\n",
    "#     )\n",
    "\n",
    "# # ---------- Sidebar ----------\n",
    "# st.sidebar.header(\"Settings\")\n",
    "# lambda_url = st.sidebar.text_input(\"AWS Lambda URL\", value=DEFAULT_LAMBDA_URL)\n",
    "# prefill = st.sidebar.selectbox(\n",
    "#     \"Prefill options\",\n",
    "#     options=[\"None\", \"Non-Fire sample\", \"Fire sample\"],\n",
    "#     index=1  # default to Non-Fire\n",
    "# )\n",
    "# st.sidebar.caption(\"Pick a prefill to load the table. You can then edit any cells or add/remove rows.\")\n",
    "\n",
    "# # ---------- Title ----------\n",
    "# st.title(\"🔥 Fire Prediction — Live Sensor Data\")\n",
    "# st.write(\"Edit the fields below and click **Prediction**. No JSON required.\")\n",
    "\n",
    "# # ---------- Session state init ----------\n",
    "# if \"table_df\" not in st.session_state:\n",
    "#     st.session_state.table_df = df_from_features_dict(NON_FIRE_SAMPLE[\"features\"])\n",
    "# if \"frame\" not in st.session_state:\n",
    "#     st.session_state.frame = NON_FIRE_SAMPLE[\"frame\"]\n",
    "# if \"timestamp\" not in st.session_state:\n",
    "#     st.session_state.timestamp = NON_FIRE_SAMPLE[\"timestamp\"]\n",
    "# if \"decision_threshold\" not in st.session_state:\n",
    "#     st.session_state.decision_threshold = NON_FIRE_SAMPLE[\"decision_threshold\"]\n",
    "\n",
    "# # ---------- Prefill logic (syncs table + metadata immediately) ----------\n",
    "# if prefill == \"Non-Fire sample\":\n",
    "#     src = NON_FIRE_SAMPLE\n",
    "# elif prefill == \"Fire sample\":\n",
    "#     src = FIRE_SAMPLE\n",
    "# else:\n",
    "#     src = None\n",
    "\n",
    "# if src is not None:\n",
    "#     st.session_state.table_df = df_from_features_dict(src[\"features\"])\n",
    "#     st.session_state.frame = src[\"frame\"]\n",
    "#     st.session_state.timestamp = src[\"timestamp\"]\n",
    "#     st.session_state.decision_threshold = src.get(\"decision_threshold\", 0.4)\n",
    "\n",
    "# # ---------- Table-only Input ----------\n",
    "# st.subheader(\"Metadata\")\n",
    "# c1, c2, c3 = st.columns([1, 1.2, 1])\n",
    "# with c1:\n",
    "#     st.session_state.frame = st.number_input(\"frame\", value=int(st.session_state.frame), step=1)\n",
    "# with c2:\n",
    "#     st.session_state.timestamp = st.text_input(\n",
    "#         \"timestamp (ISO 8601, Zulu)\",\n",
    "#         value=st.session_state.timestamp,\n",
    "#         help=\"Example: 2025-09-08T12:45:00Z\",\n",
    "#     )\n",
    "# with c3:\n",
    "#     st.session_state.decision_threshold = st.number_input(\n",
    "#         \"decision_threshold\", value=float(st.session_state.decision_threshold), step=0.05, format=\"%.4f\"\n",
    "#     )\n",
    "\n",
    "# st.subheader(\"Features (editable table)\")\n",
    "# st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
    "# st.session_state.table_df = st.data_editor(\n",
    "#     st.session_state.table_df.copy(),  # avoid inplace side-effects\n",
    "#     num_rows=\"dynamic\",\n",
    "#     use_container_width=True,\n",
    "#     hide_index=True,\n",
    "#     key=\"features_editor\"\n",
    "# )\n",
    "\n",
    "# # ---------- Controls ----------\n",
    "# run_btn = st.button(\"Prediction\", use_container_width=True, type=\"primary\")\n",
    "\n",
    "# def build_payload_from_table() -> Dict[str, Any]:\n",
    "#     feats = features_dict_from_df(st.session_state.table_df)\n",
    "#     return {\n",
    "#         \"frame\": int(st.session_state.frame),\n",
    "#         \"timestamp\": st.session_state.timestamp,\n",
    "#         \"features\": feats,\n",
    "#         \"decision_threshold\": float(st.session_state.decision_threshold),\n",
    "#     }\n",
    "\n",
    "# st.divider()\n",
    "\n",
    "# # ---------- Action ----------\n",
    "# if run_btn:\n",
    "#     try:\n",
    "#         payload = build_payload_from_table()\n",
    "#         with st.spinner(\"Contacting Lambda...\"):\n",
    "#             start = time.time()\n",
    "#             resp = call_lambda(lambda_url, payload, timeout_s=25.0)\n",
    "#             elapsed = time.time() - start\n",
    "\n",
    "#         st.success(f\"Request OK ({elapsed:.2f}s)\")\n",
    "\n",
    "#         # ----- Colored result summary -----\n",
    "#         pred = resp.get(\"prediction\", {}) or {}\n",
    "#         label = str(pred.get(\"label\", \"—\"))\n",
    "#         prob = pred.get(\"fire_probability\", None)\n",
    "#         lbl_lower = label.lower()\n",
    "\n",
    "#         # Green for Not Fire, Red for Fire\n",
    "#         if \"fire\" in lbl_lower and \"not\" not in lbl_lower:\n",
    "#             colored_box(f\"🔥 Prediction: <b>{label}</b>\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
    "#         else:\n",
    "#             colored_box(f\"✅ Prediction: <b>{label}</b>\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
    "\n",
    "#         top_cols = st.columns(3)\n",
    "#         with top_cols[0]:\n",
    "#             st.metric(\"Label\", label)\n",
    "#         with top_cols[1]:\n",
    "#             if isinstance(prob, (int, float)):\n",
    "#                 st.metric(\"Fire probability\", f\"{prob:.6f}\")\n",
    "#             else:\n",
    "#                 st.metric(\"Fire probability\", str(prob))\n",
    "#         with top_cols[2]:\n",
    "#             st.metric(\"Frame\", resp.get(\"frame\", payload.get(\"frame\", \"—\")))\n",
    "#         st.caption(f\"Timestamp: {resp.get('timestamp', payload.get('timestamp','—'))}\")\n",
    "\n",
    "#         # ----- Explanation tables (Local first, then Global) -----\n",
    "#         expl = resp.get(\"explanation\", {}) or {}\n",
    "#         lcontrib = expl.get(\"local_contributions\", [])\n",
    "#         gtf = expl.get(\"global_top_features\", [])\n",
    "\n",
    "#         if isinstance(lcontrib, list) and lcontrib:\n",
    "#             st.subheader(\"Local Contributions\")\n",
    "#             st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
    "\n",
    "#         if isinstance(gtf, list) and gtf:\n",
    "#             st.subheader(\"Global Top Features\")\n",
    "#             st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
    "\n",
    "#         # Notes (yellow box)\n",
    "#         notes = expl.get(\"notes\")\n",
    "#         if notes:\n",
    "#             colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
    "\n",
    "#     except requests.HTTPError as http_err:\n",
    "#         st.error(f\"HTTP error: {http_err}\\nResponse text: {getattr(http_err, 'response', None) and http_err.response.text}\")\n",
    "#     except Exception as e:\n",
    "#         st.error(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
