{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f29b989"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn4ziobMWtxD"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit pyngrok pandas requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eje7A6GJVb3E"
      },
      "outputs": [],
      "source": [
        "!pip -q install streamlit pyngrok pandas requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# app.py\n",
        "import time\n",
        "from typing import Any, Dict\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import streamlit as st\n",
        "\n",
        "st.set_page_config(page_title=\"Fire Prediction (4 Models)\", page_icon=\"🔥\", layout=\"wide\")\n",
        "\n",
        "# ---- Endpoints ----\n",
        "M1_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
        "M2_URL = \"https://rnmsxp5s53.us-east-1.awsapprunner.com/predict_features\"\n",
        "M3_URL = \"https://mfyemzf28h.us-east-1.awsapprunner.com/predict\"\n",
        "M4_URL = \"https://b6vmdcuw7b.execute-api.us-east-1.amazonaws.com/predict\"  # NEW\n",
        "\n",
        "# ---------- Prefills: Model 1 (Saafe model) ----------\n",
        "M1_NON_FIRE = {\n",
        "  \"frame\": 5678,\n",
        "  \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
        "  \"features\": {\n",
        "    \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
        "    \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
        "    \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
        "    \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
        "    \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
        "    \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
        "    \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
        "    \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
        "    \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
        "    \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
        "    \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
        "    \"spike_count_voc_2m\": 0,\n",
        "    \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
        "    \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
        "    \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
        "    \"is_weekend\": 0, \"asleep_window\": 0,\n",
        "    \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
        "  },\n",
        "  \"decision_threshold\": 0.4\n",
        "}\n",
        "M1_FIRE = {\n",
        "  \"frame\": 1234,\n",
        "  \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
        "  \"features\": {\n",
        "    \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
        "    \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
        "    \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
        "    \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
        "    \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
        "    \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
        "    \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
        "    \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
        "    \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
        "    \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
        "    \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
        "    \"spike_count_voc_2m\": 4,\n",
        "    \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
        "    \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
        "    \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
        "    \"is_weekend\": 0, \"asleep_window\": 1,\n",
        "    \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
        "  },\n",
        "  \"decision_threshold\": 0.4\n",
        "}\n",
        "\n",
        "# ---------- Prefills: Model 2 (18 Features research data) ----------\n",
        "M2_NON_FIRE = {\n",
        "  \"data\": {\n",
        "    \"features_dict\": {\n",
        "      \"t_mean\": 28.0, \"t_std\": 2.0, \"t_max\": 32.0, \"t_p95\": 31.0,\n",
        "      \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.0,\n",
        "      \"t_grad_mean\": 0.5, \"t_grad_std\": 0.2,\n",
        "      \"t_diff_mean\": 0.1, \"t_diff_std\": 0.05,\n",
        "      \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.05,\n",
        "      \"gas_val\": 400.0, \"gas_delta\": 5.0, \"gas_vel\": 0.5,\n",
        "      \"tproxy_val\": 32.0, \"tproxy_delta\": 1.0, \"tproxy_vel\": 0.2\n",
        "    }\n",
        "  },\n",
        "  \"threshold\": 0.5\n",
        "}\n",
        "M2_FIRE = {\n",
        "  \"data\": {\n",
        "    \"features_dict\": {\n",
        "      \"t_mean\": 105.0, \"t_std\": 15.0, \"t_max\": 160.0, \"t_p95\": 150.0,\n",
        "      \"t_hot_area_pct\": 40.0, \"t_hot_largest_blob_pct\": 30.0,\n",
        "      \"t_grad_mean\": 12.0, \"t_grad_std\": 6.0,\n",
        "      \"t_diff_mean\": 8.0, \"t_diff_std\": 4.0,\n",
        "      \"flow_mag_mean\": 5.0, \"flow_mag_std\": 2.0,\n",
        "      \"gas_val\": 2500.0, \"gas_delta\": 600.0, \"gas_vel\": 600.0,\n",
        "      \"tproxy_val\": 160.0, \"tproxy_delta\": 20.0, \"tproxy_vel\": 20.0\n",
        "    }\n",
        "  },\n",
        "  \"threshold\": 0.5\n",
        "}\n",
        "\n",
        "# ---------- Prefills: Model 3 (Kaggle Base model) ----------\n",
        "M3_NON_FIRE = {\n",
        "  \"data\": {\n",
        "    \"Temperature[C]\": 23.5, \"Humidity[%]\": 42, \"TVOC[ppb]\": 3, \"eCO2[ppm]\": 420,\n",
        "    \"PM1.0\": 1.2, \"PM2.5\": 2.3, \"PM10\": 3.4, \"Pressure[hPa]\": 1013.2,\n",
        "    \"Raw H2\": 14500, \"Raw Ethanol\": 21000, \"CNT\": 0, \"UTC\": 0,\n",
        "    \"NC0.5\": 0, \"NC1.0\": 0, \"NC2.5\": 0\n",
        "  }\n",
        "}\n",
        "M3_FIRE = {\n",
        "  \"data\": {\n",
        "    \"Temperature[C]\": 45.7, \"Humidity[%]\": 15.3, \"TVOC[ppb]\": 850, \"eCO2[ppm]\": 2200,\n",
        "    \"PM1.0\": 80.1, \"PM2.5\": 120.5, \"PM10\": 155.0, \"Pressure[hPa]\": 1002.1,\n",
        "    \"Raw H2\": 30000, \"Raw Ethanol\": 42000, \"CNT\": 123456, \"UTC\": 1623859200,\n",
        "    \"NC0.5\": 3500, \"NC1.0\": 2100, \"NC2.5\": 1500\n",
        "  }\n",
        "}\n",
        "\n",
        "# ---------- Prefills: Model 4 (Tensorflow enhanced) ----------\n",
        "M4_FIRE = {\n",
        "  \"frame\": 1234,\n",
        "  \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
        "  \"features\": {\n",
        "    \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
        "    \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
        "    \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
        "    \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
        "    \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
        "    \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
        "    \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
        "    \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
        "    \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
        "    \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
        "    \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
        "    \"spike_count_voc_2m\": 4,\n",
        "    \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
        "    \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
        "    \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
        "    \"is_weekend\": 0, \"asleep_window\": 1,\n",
        "    \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
        "  },\n",
        "  \"decision_threshold\": 0.4\n",
        "}\n",
        "M4_NON_FIRE = {\n",
        "  \"frame\": 9012,\n",
        "  \"timestamp\": \"2025-09-08T13:10:00Z\",\n",
        "  \"features\": {\n",
        "    \"t_mean\": 22.0, \"t_std\": 0.1, \"t_max\": 22.3, \"t_p95\": 22.2,\n",
        "    \"t_hot_area_pct\": 0.0, \"t_hot_largest_blob_pct\": 0.0,\n",
        "\n",
        "    \"t_grad_mean\": 0.0, \"t_grad_std\": 0.0,\n",
        "    \"t_diff_mean\": 0.0, \"t_diff_std\": 0.0,\n",
        "\n",
        "    \"flow_mag_mean\": 0.02, \"flow_mag_std\": 0.002,\n",
        "\n",
        "    \"tproxy_val\": 22.1, \"tproxy_delta\": 0.0, \"tproxy_vel\": 0.0,\n",
        "\n",
        "    \"CO\": 0.03, \"VOC\": 0.06, \"NO2\": 0.004,\n",
        "    \"CO_diff\": -0.001, \"VOC_diff\": -0.001, \"NO2_diff\": 0.0,\n",
        "    \"VOC_ma5\": 0.06, \"CO_ma5\": 0.03, \"NO2_ma5\": 0.004,\n",
        "\n",
        "    \"VOC_z\": -0.15, \"CO_z\": -0.15, \"NO2_z\": -0.05,\n",
        "\n",
        "    \"temp_rise_c_per_min\": 0.0, \"temp_slope_30s\": 0.0,\n",
        "    \"gas_var_30s\": 0.0, \"delta_temp_30s\": 0.0, \"delta_gas_10s\": 0.0,\n",
        "    \"spike_count_voc_2m\": 0,\n",
        "\n",
        "    \"temp_co_corr_lag_0s\": 0.0, \"temp_co_corr_lag_15s\": 0.0, \"temp_co_corr_lag_60s\": 0.0,\n",
        "    \"temp_voc_corr_lag_0s\": 0.0, \"temp_voc_corr_lag_15s\": 0.0, \"temp_voc_corr_lag_60s\": 0.0,\n",
        "    \"temp_co_xcorr_max_abs\": 0.005, \"temp_voc_xcorr_max_abs\": 0.005,\n",
        "\n",
        "    \"is_weekend\": 0, \"asleep_window\": 0,\n",
        "\n",
        "    \"hrblk_0\": 0, \"hrblk_1\": 1, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
        "  },\n",
        "  \"decision_threshold\": 0.40\n",
        "}\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def coerce_value(v: Any) -> Any:\n",
        "    if isinstance(v, str):\n",
        "        if v.strip() == \"\":\n",
        "            return v\n",
        "        try:\n",
        "            if \".\" in v or \"e\" in v.lower():\n",
        "                return float(v)\n",
        "            return int(v)\n",
        "        except Exception:\n",
        "            return v\n",
        "    return v\n",
        "\n",
        "def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
        "    items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
        "    return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
        "\n",
        "def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "    out = {}\n",
        "    for _, row in df.iterrows():\n",
        "        key = str(row.get(\"feature\", \"\")).strip()\n",
        "        if not key:\n",
        "            continue\n",
        "        out[key] = coerce_value(row.get(\"value\"))\n",
        "    return out\n",
        "\n",
        "def post_json(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
        "    r = requests.post(url, json=payload, timeout=timeout_s)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <div style=\"\n",
        "            padding: 12px 14px; border-radius: 8px;\n",
        "            background: {bg}; color: {color}; border: 1px solid {border};\n",
        "            font-weight: 500;\">\n",
        "            {text}\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "def html_summary_table(rows, key_to_color=None):\n",
        "    \"\"\"\n",
        "    rows: List[Tuple[field, value]]\n",
        "    key_to_color: dict like {\"Label\": (\"red\"|\"green\"|\"none\", condition_bool)} is ignored;\n",
        "                  we color based on value semantics below.\n",
        "    \"\"\"\n",
        "    def cell_style(field, val):\n",
        "        # Model 1/4: Label\n",
        "        if field.lower() == \"label\":\n",
        "            if isinstance(val, str) and val.strip().lower() == \"fire\":\n",
        "                return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
        "            if isinstance(val, str) and val.strip().lower() == \"not fire\":\n",
        "                return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
        "        # Model 2: fire_detected\n",
        "        if field == \"fire_detected\":\n",
        "            if val is True:\n",
        "                return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
        "            if val is False:\n",
        "                return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
        "        # Model 3: fire_prediction\n",
        "        if field == \"fire_prediction\":\n",
        "            if val is True:\n",
        "                return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
        "            if val is False:\n",
        "                return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
        "        return \"\"\n",
        "    html = ['<table style=\"width:100%;border-collapse:collapse;\">']\n",
        "    for field, val in rows:\n",
        "        style = cell_style(field, val)\n",
        "        html.append(\n",
        "            f'<tr>'\n",
        "            f'<td style=\"border:1px solid #ddd;padding:8px;width:35%;font-weight:600;background:#fafafa;\">{field}</td>'\n",
        "            f'<td style=\"border:1px solid #ddd;padding:8px;{style}\">{val}</td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "    html.append('</table>')\n",
        "    st.markdown(\"\".join(html), unsafe_allow_html=True)\n",
        "\n",
        "# ========================= Email Notification System =========================\n",
        "# Session state for email deduplication\n",
        "if 'last_fire_alerts' not in st.session_state:\n",
        "    st.session_state.last_fire_alerts = {}\n",
        "\n",
        "def should_send_alert(model_name: str, prediction_data: Dict[str, Any]) -> bool:\n",
        "    \"\"\"Check if we should send an alert to avoid duplicates\"\"\"\n",
        "    # Create a simple hash of the prediction data\n",
        "    pred_hash = hash(str(sorted(prediction_data.items())))\n",
        "\n",
        "    # Check if we've already sent an alert for this prediction\n",
        "    last_alert = st.session_state.last_fire_alerts.get(model_name)\n",
        "    if last_alert == pred_hash:\n",
        "        return False\n",
        "\n",
        "    # Update the last alert hash\n",
        "    st.session_state.last_fire_alerts[model_name] = pred_hash\n",
        "    return True\n",
        "\n",
        "def send_fire_alert_email(model_name: str, prediction_data: Dict[str, Any], email_config: Dict[str, str]):\n",
        "    \"\"\"Send an email alert when fire is detected\"\"\"\n",
        "    try:\n",
        "        # Create message\n",
        "        msg = MIMEMultipart()\n",
        "        msg['From'] = email_config['sender_email']\n",
        "        msg['To'] = email_config['recipient_email']\n",
        "        msg['Subject'] = f\"🔥 FIRE ALERT - {model_name} Detected Fire\"\n",
        "\n",
        "        # Format prediction data for email\n",
        "        prediction_str = \"\\n\".join([f\"{k}: {v}\" for k, v in prediction_data.items()])\n",
        "\n",
        "        # Create email body\n",
        "        body = f\"\"\"\n",
        "FIRE DETECTED by {model_name}!\n",
        "\n",
        "Prediction Details:\n",
        "{prediction_str}\n",
        "\n",
        "Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "Please take immediate action.\n",
        "\"\"\"\n",
        "\n",
        "        msg.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "        # Create SMTP session\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(email_config['sender_email'], email_config['sender_password'])\n",
        "\n",
        "        # Send email\n",
        "        text = msg.as_string()\n",
        "        server.sendmail(email_config['sender_email'], email_config['recipient_email'], text)\n",
        "        server.quit()\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email: {e}\")\n",
        "        return False\n",
        "\n",
        "# ========================= UI =========================\n",
        "st.title(\"🔥 Fire Prediction — Live data\")\n",
        "\n",
        "# ========================= EMAIL CONFIGURATION =========================\n",
        "st.sidebar.header(\"📧 Email Notifications\")\n",
        "enable_email = st.sidebar.checkbox(\"Enable Email Alerts\", value=False)\n",
        "sender_email = st.sidebar.text_input(\"Sender Email (Gmail)\", placeholder=\"your_email@gmail.com\")\n",
        "sender_password = st.sidebar.text_input(\"App Password\", type=\"password\", placeholder=\"Gmail App Password\")\n",
        "recipient_email = st.sidebar.text_input(\"Recipient Email\", value=\"ch.ajay1707@gmail.com\")\n",
        "\n",
        "# Test email configuration\n",
        "if st.sidebar.button(\"Test Email Configuration\"):\n",
        "    if sender_email and sender_password and recipient_email:\n",
        "        test_config = {\n",
        "            'sender_email': sender_email,\n",
        "            'sender_password': sender_password,\n",
        "            'recipient_email': recipient_email\n",
        "        }\n",
        "        # Send test email\n",
        "        test_data = {\"status\": \"Test email from Fire Prediction App\", \"result\": \"Configuration successful\"}\n",
        "        email_sent = send_fire_alert_email(\"Test Notification\", test_data, test_config)\n",
        "        if email_sent:\n",
        "            st.sidebar.success(\"✅ Test email sent successfully!\")\n",
        "        else:\n",
        "            st.sidebar.error(\"❌ Failed to send test email. Check your configuration.\")\n",
        "    else:\n",
        "        st.sidebar.warning(\"Please fill in all email fields first.\")\n",
        "\n",
        "st.sidebar.caption(\"Note: Use Gmail App Passwords for security. Enable 2FA and generate an app password.\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "    **Setup Instructions:**\n",
        "    1. Enable 2-Factor Authentication on your Gmail account\n",
        "    2. Generate an App Password in your Google Account settings\n",
        "    3. Enter your Gmail address and App Password above\n",
        "    4. Verify the recipient email is correct\n",
        "    5. Click 'Test Email Configuration' to verify\n",
        "    6. Enable email alerts\n",
        "\"\"\")\n",
        "\n",
        "# Store email config in session state\n",
        "email_config = {\n",
        "    'sender_email': sender_email,\n",
        "    'sender_password': sender_password,\n",
        "    'recipient_email': recipient_email\n",
        "}\n",
        "\n",
        "tabs = st.tabs([\n",
        "    \"Live data fire prediction\",\n",
        "    \"18 Features research data\",\n",
        "    \"Kaggle Base model\",\n",
        "    \"Tensorflow enhanced\"  # NEW\n",
        "])\n",
        "\n",
        "# ========================= Model 1 =========================\n",
        "with tabs[0]:\n",
        "    st.subheader(\"Fire prediction live data\")\n",
        "    left, right = st.columns([1, 1])\n",
        "    with left:\n",
        "        m1_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m1_prefill\")\n",
        "    with right:\n",
        "        m1_url = st.text_input(\"Endpoint\", value=M1_URL, key=\"m1_endpoint\")\n",
        "\n",
        "    # Session defaults\n",
        "    if \"m1_frame\" not in st.session_state:\n",
        "        st.session_state.m1_frame = M1_NON_FIRE[\"frame\"]\n",
        "    if \"m1_timestamp\" not in st.session_state:\n",
        "        st.session_state.m1_timestamp = M1_NON_FIRE[\"timestamp\"]\n",
        "    if \"m1_threshold\" not in st.session_state:\n",
        "        st.session_state.m1_threshold = M1_NON_FIRE[\"decision_threshold\"]\n",
        "    if \"m1_table\" not in st.session_state:\n",
        "        st.session_state.m1_table = df_from_features_dict(M1_NON_FIRE[\"features\"])\n",
        "\n",
        "    # Prefill\n",
        "    src1 = M1_NON_FIRE if m1_prefill == \"Non-Fire sample\" else M1_FIRE if m1_prefill == \"Fire sample\" else None\n",
        "    if src1 is not None:\n",
        "        st.session_state.m1_frame = src1[\"frame\"]\n",
        "        st.session_state.m1_timestamp = src1[\"timestamp\"]\n",
        "        st.session_state.m1_threshold = src1.get(\"decision_threshold\", 0.4)\n",
        "        st.session_state.m1_table = df_from_features_dict(src1[\"features\"])\n",
        "\n",
        "    st.markdown(\"**Metadata**\")\n",
        "    c1, c2, c3 = st.columns([1, 1.2, 1])\n",
        "    with c1:\n",
        "        st.session_state.m1_frame = st.number_input(\"frame\", value=int(st.session_state.m1_frame), step=1, key=\"m1_frame_input\")\n",
        "    with c2:\n",
        "        st.session_state.m1_timestamp = st.text_input(\"timestamp (ISO 8601, Zulu)\", value=st.session_state.m1_timestamp, key=\"m1_ts_input\")\n",
        "    with c3:\n",
        "        st.session_state.m1_threshold = st.number_input(\"decision_threshold\", value=float(st.session_state.m1_threshold), step=0.05, format=\"%.4f\", key=\"m1_thr_input\")\n",
        "\n",
        "    st.markdown(\"**Features (editable table)**\")\n",
        "    st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
        "    st.session_state.m1_table = st.data_editor(\n",
        "        st.session_state.m1_table.copy(),\n",
        "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m1_features_editor\"\n",
        "    )\n",
        "\n",
        "    m1_run = st.button(\"Prediction (Saafe model)\", type=\"primary\", use_container_width=True, key=\"m1_run_btn\")\n",
        "    st.divider()\n",
        "\n",
        "    if m1_run:\n",
        "        try:\n",
        "            payload1 = {\n",
        "                \"frame\": int(st.session_state.m1_frame),\n",
        "                \"timestamp\": st.session_state.m1_timestamp,\n",
        "                \"features\": features_dict_from_df(st.session_state.m1_table),\n",
        "                \"decision_threshold\": float(st.session_state.m1_threshold),\n",
        "            }\n",
        "            with st.spinner(\"Calling AWS Lambda...\"):\n",
        "                t0 = time.time()\n",
        "                resp1 = post_json(m1_url, payload1, timeout_s=25.0)\n",
        "                elapsed = time.time() - t0\n",
        "\n",
        "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "            # Colored banner + summary table (Label cell colored)\n",
        "            pred = resp1.get(\"prediction\", {}) or {}\n",
        "            lbl = str(pred.get(\"label\", \"\")).lower()\n",
        "            fire_detected = \"fire\" in lbl and \"not\" not in lbl\n",
        "\n",
        "            if fire_detected:\n",
        "                colored_box(\"🔥 Fire detected by Saafe model\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "                # Send email alert if enabled and not a duplicate\n",
        "                if enable_email and sender_email and sender_password and recipient_email:\n",
        "                    if should_send_alert(\"Saafe Model\", pred):\n",
        "                        email_sent = send_fire_alert_email(\"Saafe Model\", pred, email_config)\n",
        "                        if email_sent:\n",
        "                            st.success(\"📧 Fire alert email sent successfully!\")\n",
        "                        else:\n",
        "                            st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "                    else:\n",
        "                        st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "            else:\n",
        "                colored_box(\"✅ Not Fire (Saafe model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "            st.subheader(\"Prediction Summary\")\n",
        "            summary_rows = [\n",
        "                (\"Label\", str(pred.get(\"label\", \"—\"))),\n",
        "                (\"Fire probability\", f\"{pred.get('fire_probability'):.6f}\" if isinstance(pred.get(\"fire_probability\"), (int, float)) else str(pred.get(\"fire_probability\"))),\n",
        "                (\"Frame\", resp1.get(\"frame\", payload1[\"frame\"])),\n",
        "                (\"Timestamp\", resp1.get(\"timestamp\", payload1[\"timestamp\"])),\n",
        "            ]\n",
        "            html_summary_table(summary_rows)\n",
        "\n",
        "            # Explanation tables — Local first, then Global\n",
        "            expl = resp1.get(\"explanation\", {}) or {}\n",
        "            lcontrib = expl.get(\"local_contributions\", [])\n",
        "            gtf = expl.get(\"global_top_features\", [])\n",
        "\n",
        "            if isinstance(lcontrib, list) and lcontrib:\n",
        "                st.subheader(\"Local Contributions\")\n",
        "                st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
        "\n",
        "            if isinstance(gtf, list) and gtf:\n",
        "                st.subheader(\"Global Top Features\")\n",
        "                st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
        "\n",
        "            notes = expl.get(\"notes\")\n",
        "            if notes:\n",
        "                colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
        "\n",
        "        except requests.HTTPError as e:\n",
        "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {e}\")\n",
        "\n",
        "# ========================= Model 2 =========================\n",
        "with tabs[1]:\n",
        "    st.subheader(\"18 Features research data\")\n",
        "    left, right = st.columns([1, 1])\n",
        "    with left:\n",
        "        m2_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m2_prefill\")\n",
        "    with right:\n",
        "        m2_url = st.text_input(\"Endpoint\", value=M2_URL, key=\"m2_endpoint\")\n",
        "\n",
        "    if \"m2_threshold\" not in st.session_state:\n",
        "        st.session_state.m2_threshold = float(M2_NON_FIRE[\"threshold\"])\n",
        "    if \"m2_table\" not in st.session_state:\n",
        "        st.session_state.m2_table = df_from_features_dict(M2_NON_FIRE[\"data\"][\"features_dict\"])\n",
        "\n",
        "    src2 = M2_NON_FIRE if m2_prefill == \"Non-Fire sample\" else M2_FIRE if m2_prefill == \"Fire sample\" else None\n",
        "    if src2 is not None:\n",
        "        st.session_state.m2_threshold = float(src2.get(\"threshold\", 0.5))\n",
        "        st.session_state.m2_table = df_from_features_dict(src2[\"data\"][\"features_dict\"])\n",
        "\n",
        "    st.markdown(\"**Threshold**\")\n",
        "    st.session_state.m2_threshold = st.number_input(\"threshold\", value=float(st.session_state.m2_threshold), step=0.05, format=\"%.2f\", key=\"m2_thr_input\")\n",
        "\n",
        "    st.markdown(\"**Features (editable table)**\")\n",
        "    st.caption(\"Exactly 18 core features expected by this API.\")\n",
        "    st.session_state.m2_table = st.data_editor(\n",
        "        st.session_state.m2_table.copy(),\n",
        "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m2_features_editor\"\n",
        "    )\n",
        "\n",
        "    m2_run = st.button(\"Prediction (18 Features)\", type=\"primary\", use_container_width=True, key=\"m2_run_btn\")\n",
        "    st.divider()\n",
        "\n",
        "    if m2_run:\n",
        "        try:\n",
        "            payload2 = {\n",
        "                \"data\": {\"features_dict\": features_dict_from_df(st.session_state.m2_table)},\n",
        "                \"threshold\": float(st.session_state.m2_threshold),\n",
        "            }\n",
        "            with st.spinner(\"Calling 18-Features API...\"):\n",
        "                t0 = time.time()\n",
        "                resp2 = post_json(m2_url, payload2, timeout_s=25.0)\n",
        "                elapsed = time.time() - t0\n",
        "\n",
        "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "            # Banner FIRST (as requested)\n",
        "            fire_detected = bool(resp2.get(\"fire_detected\", False))\n",
        "            if fire_detected:\n",
        "                colored_box(\"🔥 Fire detected (18 Features)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "                # Send email alert if enabled and not a duplicate\n",
        "                if enable_email and sender_email and sender_password and recipient_email:\n",
        "                    if should_send_alert(\"18 Features Model\", resp2):\n",
        "                        email_sent = send_fire_alert_email(\"18 Features Model\", resp2, email_config)\n",
        "                        if email_sent:\n",
        "                            st.success(\"📧 Fire alert email sent successfully!\")\n",
        "                        else:\n",
        "                            st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "                    else:\n",
        "                        st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "            else:\n",
        "                colored_box(\"✅ Not Fire (18 Features)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "            # Summary table with colored fire_detected cell\n",
        "            st.subheader(\"Prediction Summary\")\n",
        "            rows = [\n",
        "                (\"fire_detected\", bool(resp2.get(\"fire_detected\", False))),\n",
        "                (\"score\", f\"{resp2.get('score'):.6f}\" if isinstance(resp2.get(\"score\"), (int, float)) else str(resp2.get(\"score\"))),\n",
        "                (\"latency_ms\", f\"{resp2.get('latency_ms'):.3f}\" if isinstance(resp2.get(\"latency_ms\"), (int, float)) else str(resp2.get(\"latency_ms\"))),\n",
        "            ]\n",
        "            html_summary_table(rows)\n",
        "\n",
        "        except requests.HTTPError as e:\n",
        "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {e}\")\n",
        "\n",
        "# ========================= Model 3 =========================\n",
        "with tabs[2]:\n",
        "    st.subheader(\"Kaggle Base model\")\n",
        "    left, right = st.columns([1, 1])\n",
        "    with left:\n",
        "        m3_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m3_prefill\")\n",
        "    with right:\n",
        "        m3_url = st.text_input(\"Endpoint\", value=M3_URL, key=\"m3_endpoint\")\n",
        "\n",
        "    if \"m3_table\" not in st.session_state:\n",
        "        st.session_state.m3_table = df_from_features_dict(M3_NON_FIRE[\"data\"])\n",
        "\n",
        "    # Prefill\n",
        "    src3 = M3_NON_FIRE if m3_prefill == \"Non-Fire sample\" else M3_FIRE if m3_prefill == \"Fire sample\" else None\n",
        "    if src3 is not None:\n",
        "        st.session_state.m3_table = df_from_features_dict(src3[\"data\"])\n",
        "\n",
        "    st.markdown(\"**Features (editable table)**\")\n",
        "    st.caption(\"Kaggle Base model sensor set.\")\n",
        "    st.session_state.m3_table = st.data_editor(\n",
        "        st.session_state.m3_table.copy(),\n",
        "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m3_features_editor\"\n",
        "    )\n",
        "\n",
        "    m3_run = st.button(\"Prediction (Kaggle Base)\", type=\"primary\", use_container_width=True, key=\"m3_run_btn\")\n",
        "    st.divider()\n",
        "\n",
        "    if m3_run:\n",
        "        try:\n",
        "            payload3 = {\"data\": features_dict_from_df(st.session_state.m3_table)}\n",
        "            with st.spinner(\"Calling Kaggle Base API...\"):\n",
        "                t0 = time.time()\n",
        "                resp3 = post_json(m3_url, payload3, timeout_s=25.0)\n",
        "                elapsed = time.time() - t0\n",
        "\n",
        "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "            # Banner FIRST (as requested)\n",
        "            fire_detected = bool(resp3.get(\"fire_prediction\", False))\n",
        "            if fire_detected:\n",
        "                colored_box(\"🔥 Fire detected (Kaggle Base model)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "                # Send email alert if enabled and not a duplicate\n",
        "                if enable_email and sender_email and sender_password and recipient_email:\n",
        "                    if should_send_alert(\"Kaggle Base Model\", resp3):\n",
        "                        email_sent = send_fire_alert_email(\"Kaggle Base Model\", resp3, email_config)\n",
        "                        if email_sent:\n",
        "                            st.success(\"📧 Fire alert email sent successfully!\")\n",
        "                        else:\n",
        "                            st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "                    else:\n",
        "                        st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "            else:\n",
        "                colored_box(\"✅ Not Fire (Kaggle Base model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "            # Summary table with colored fire_prediction cell\n",
        "            st.subheader(\"Prediction Summary\")\n",
        "            rows = [\n",
        "                (\"fire_prediction\", bool(resp3.get(\"fire_prediction\", False))),\n",
        "                (\"score\", f\"{resp3.get('score'):.12f}\" if isinstance(resp3.get(\"score\"), (int, float)) else str(resp3.get(\"score\"))),\n",
        "                (\"latency_ms\", f\"{resp3.get('latency_ms'):.3f}\" if isinstance(resp3.get(\"latency_ms\"), (int, float)) else str(resp3.get(\"latency_ms\"))),\n",
        "            ]\n",
        "            html_summary_table(rows)\n",
        "\n",
        "        except requests.HTTPError as e:\n",
        "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {e}\")\n",
        "\n",
        "# ========================= Model 4 =========================\n",
        "with tabs[3]:\n",
        "    st.subheader(\"Tensorflow enhanced\")\n",
        "    left, right = st.columns([1, 1])\n",
        "    with left:\n",
        "        m4_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m4_prefill\")\n",
        "    with right:\n",
        "        m4_url = st.text_input(\"Endpoint\", value=M4_URL, key=\"m4_endpoint\")\n",
        "\n",
        "    # Session defaults\n",
        "    if \"m4_frame\" not in st.session_state:\n",
        "        st.session_state.m4_frame = M4_NON_FIRE[\"frame\"]\n",
        "    if \"m4_timestamp\" not in st.session_state:\n",
        "        st.session_state.m4_timestamp = M4_NON_FIRE[\"timestamp\"]\n",
        "    if \"m4_threshold\" not in st.session_state:\n",
        "        st.session_state.m4_threshold = M4_NON_FIRE[\"decision_threshold\"]\n",
        "    if \"m4_table\" not in st.session_state:\n",
        "        st.session_state.m4_table = df_from_features_dict(M4_NON_FIRE[\"features\"])\n",
        "\n",
        "    # Prefill\n",
        "    src4 = M4_NON_FIRE if m4_prefill == \"Non-Fire sample\" else M4_FIRE if m4_prefill == \"Fire sample\" else None\n",
        "    if src4 is not None:\n",
        "        st.session_state.m4_frame = src4[\"frame\"]\n",
        "        st.session_state.m4_timestamp = src4[\"timestamp\"]\n",
        "        st.session_state.m4_threshold = src4.get(\"decision_threshold\", 0.4)\n",
        "        st.session_state.m4_table = df_from_features_dict(src4[\"features\"])\n",
        "\n",
        "    st.markdown(\"**Metadata**\")\n",
        "    c1, c2, c3 = st.columns([1, 1.2, 1])\n",
        "    with c1:\n",
        "        st.session_state.m4_frame = st.number_input(\"frame\", value=int(st.session_state.m4_frame), step=1, key=\"m4_frame_input\")\n",
        "    with c2:\n",
        "        st.session_state.m4_timestamp = st.text_input(\"timestamp (ISO 8601, Zulu)\", value=st.session_state.m4_timestamp, key=\"m4_ts_input\")\n",
        "    with c3:\n",
        "        st.session_state.m4_threshold = st.number_input(\"decision_threshold\", value=float(st.session_state.m4_threshold), step=0.05, format=\"%.4f\", key=\"m4_thr_input\")\n",
        "\n",
        "    st.markdown(\"**Features (editable table)**\")\n",
        "    st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
        "    st.session_state.m4_table = st.data_editor(\n",
        "        st.session_state.m4_table.copy(),\n",
        "        num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m4_features_editor\"\n",
        "    )\n",
        "\n",
        "    m4_run = st.button(\"Prediction (Tensorflow enhanced)\", type=\"primary\", use_container_width=True, key=\"m4_run_btn\")\n",
        "    st.divider()\n",
        "\n",
        "    if m4_run:\n",
        "        try:\n",
        "            payload4 = {\n",
        "                \"frame\": int(st.session_state.m4_frame),\n",
        "                \"timestamp\": st.session_state.m4_timestamp,\n",
        "                \"features\": features_dict_from_df(st.session_state.m4_table),\n",
        "                \"decision_threshold\": float(st.session_state.m4_threshold),\n",
        "            }\n",
        "            with st.spinner(\"Calling Tensorflow enhanced API...\"):\n",
        "                t0 = time.time()\n",
        "                resp4 = post_json(m4_url, payload4, timeout_s=25.0)\n",
        "                elapsed = time.time() - t0\n",
        "\n",
        "            st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "            # Banner + email alerts (same semantics as Model 1)\n",
        "            pred4 = resp4.get(\"prediction\", {}) or {}\n",
        "            lbl4 = str(pred4.get(\"label\", \"\")).lower()\n",
        "            fire4 = \"fire\" in lbl4 and \"not\" not in lbl4\n",
        "\n",
        "            if fire4:\n",
        "                colored_box(\"🔥 Fire detected (Tensorflow enhanced)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "                if enable_email and sender_email and sender_password and recipient_email:\n",
        "                    if should_send_alert(\"Tensorflow Enhanced\", pred4):\n",
        "                        email_sent = send_fire_alert_email(\"Tensorflow Enhanced\", pred4, email_config)\n",
        "                        if email_sent:\n",
        "                            st.success(\"📧 Fire alert email sent successfully!\")\n",
        "                        else:\n",
        "                            st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "                    else:\n",
        "                        st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "            else:\n",
        "                colored_box(\"✅ Not Fire (Tensorflow enhanced)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "            # Summary\n",
        "            st.subheader(\"Prediction Summary\")\n",
        "            summary_rows4 = [\n",
        "                (\"Label\", str(pred4.get(\"label\", \"—\"))),\n",
        "                (\"Fire probability\", f\"{pred4.get('fire_probability'):.6f}\" if isinstance(pred4.get(\"fire_probability\"), (int, float)) else str(pred4.get(\"fire_probability\"))),\n",
        "                (\"Frame\", resp4.get(\"frame\", payload4[\"frame\"])),\n",
        "                (\"Timestamp\", resp4.get(\"timestamp\", payload4[\"timestamp\"])),\n",
        "            ]\n",
        "            html_summary_table(summary_rows4)\n",
        "\n",
        "            # Explanations if present\n",
        "            expl4 = resp4.get(\"explanation\", {}) or {}\n",
        "            lcontrib4 = expl4.get(\"local_contributions\", [])\n",
        "            gtf4 = expl4.get(\"global_top_features\", [])\n",
        "\n",
        "            if isinstance(lcontrib4, list) and lcontrib4:\n",
        "                st.subheader(\"Local Contributions\")\n",
        "                st.dataframe(pd.DataFrame(lcontrib4), use_container_width=True)\n",
        "\n",
        "            if isinstance(gtf4, list) and gtf4:\n",
        "                st.subheader(\"Global Top Features\")\n",
        "                st.dataframe(pd.DataFrame(gtf4), use_container_width=True)\n",
        "\n",
        "            notes4 = expl4.get(\"notes\")\n",
        "            if notes4:\n",
        "                colored_box(f\"📝 {notes4}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
        "\n",
        "        except requests.HTTPError as e:\n",
        "            st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRutJAo-0IUH",
        "outputId": "e8d1db50-7f82-425c-b790-ace587309853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr3XGxdQVyg-",
        "outputId": "0a46400a-92bd-47e0-9e28-38773d183ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Kill any previous processes (ignore errors if none)\n",
        "!pkill -f streamlit || true\n",
        "!pkill -f ngrok || true\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7kzPKVQKdjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OdVn6kfX7Qi",
        "outputId": "4e6ea799-54d6-4f4c-d143-c85bd10d965c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Streamlit log (tail) ----\n",
            "\n",
            "  Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "    You can now view your Streamlit app in your browser.\n",
            "\n",
            "    URL: http://0.0.0.0:8502\n",
            "\n",
            "\n",
            "\n",
            "🌍 Public URL: NgrokTunnel: \"https://5777fa1273c8.ngrok-free.app\" -> \"http://localhost:8502\"\n",
            "⚙️  Internal target: http://localhost:8502\n",
            "\n",
            "Open the 🌍 Public URL in your browser (NOT localhost).\n"
          ]
        }
      ],
      "source": [
        "import os, socket, subprocess, time, textwrap\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ----- your ngrok token -----\n",
        "NGROK_TOKEN = \"2xmWjT1LoIIVYxxXxDBeHpYaOZz_3Z9VdDRCJvjMvsRGdbzGZ\"\n",
        "\n",
        "# Ensure app.py exists; if not, stop here\n",
        "assert os.path.exists(\"app.py\"), \"app.py not found. Make sure you saved the Streamlit app.\"\n",
        "\n",
        "# Find a free port starting at 8501\n",
        "def get_free_port(start=8501, tries=30):\n",
        "    for p in range(start, start+tries):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "            try:\n",
        "                s.bind((\"\", p))\n",
        "                return p\n",
        "            except OSError:\n",
        "                continue\n",
        "    raise RuntimeError(\"No free port found\")\n",
        "\n",
        "port = get_free_port()\n",
        "\n",
        "# Start Streamlit in background and log to file\n",
        "logfile = \"/tmp/streamlit.log\"\n",
        "if os.path.exists(logfile):\n",
        "    os.remove(logfile)\n",
        "\n",
        "proc = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"0.0.0.0\", \"--server.port\", str(port)],\n",
        "    stdout=open(logfile, \"w\"), stderr=subprocess.STDOUT, env=os.environ.copy()\n",
        ")\n",
        "\n",
        "# Wait a bit for Streamlit to boot\n",
        "time.sleep(4)\n",
        "\n",
        "# Show the last lines of the log (useful if there's an error)\n",
        "print(\"---- Streamlit log (tail) ----\")\n",
        "if os.path.exists(logfile):\n",
        "    print(textwrap.indent(\"\".join(open(logfile).read().splitlines(True)[-60:]), \"  \"))\n",
        "else:\n",
        "    print(\"  (no log yet)\")\n",
        "\n",
        "# Start a fresh ngrok agent and open ONE tunnel\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "public_url = ngrok.connect(port)\n",
        "print(\"\\n🌍 Public URL:\", public_url)\n",
        "print(f\"⚙️  Internal target: http://localhost:{port}\")\n",
        "print(\"\\nOpen the 🌍 Public URL in your browser (NOT localhost).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKHmKmNiejky"
      },
      "outputs": [],
      "source": [
        "# %%writefile app.py\n",
        "# import time\n",
        "# from typing import Any, Dict\n",
        "# import smtplib\n",
        "# from email.mime.text import MIMEText\n",
        "# from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "# import pandas as pd\n",
        "# import requests\n",
        "# import streamlit as st\n",
        "\n",
        "# st.set_page_config(page_title=\"Fire Prediction (3 Models)\", page_icon=\"🔥\", layout=\"wide\")\n",
        "\n",
        "# # ---- Endpoints ----\n",
        "# M1_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
        "# M2_URL = \"https://rnmsxp5s53.us-east-1.awsapprunner.com/predict_features\"\n",
        "# M3_URL = \"https://mfyemzf28h.us-east-1.awsapprunner.com/predict\"\n",
        "# M4_URL = \"https://b6vmdcuw7b.execute-api.us-east-1.amazonaws.com/predict\"\n",
        "\n",
        "# # ---------- Prefills: Model 1 (Saafe model) ----------\n",
        "# M1_NON_FIRE = {\n",
        "#   \"frame\": 5678,\n",
        "#   \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
        "#   \"features\": {\n",
        "#     \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
        "#     \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
        "#     \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
        "#     \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
        "#     \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
        "#     \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
        "#     \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
        "#     \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
        "#     \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
        "#     \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
        "#     \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
        "#     \"spike_count_voc_2m\": 0,\n",
        "#     \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
        "#     \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
        "#     \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
        "#     \"is_weekend\": 0, \"asleep_window\": 0,\n",
        "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
        "#   },\n",
        "#   \"decision_threshold\": 0.4\n",
        "# }\n",
        "# M1_FIRE = {\n",
        "#   \"frame\": 1234,\n",
        "#   \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
        "#   \"features\": {\n",
        "#     \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
        "#     \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
        "#     \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
        "#     \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
        "#     \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
        "#     \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
        "#     \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
        "#     \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
        "#     \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
        "#     \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
        "#     \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
        "#     \"spike_count_voc_2m\": 4,\n",
        "#     \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
        "#     \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
        "#     \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
        "#     \"is_weekend\": 0, \"asleep_window\": 1,\n",
        "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
        "#   },\n",
        "#   \"decision_threshold\": 0.4\n",
        "# }\n",
        "\n",
        "# # ---------- Prefills: Model 2 (18 Features research data) ----------\n",
        "# M2_NON_FIRE = {\n",
        "#   \"data\": {\n",
        "#     \"features_dict\": {\n",
        "#       \"t_mean\": 28.0, \"t_std\": 2.0, \"t_max\": 32.0, \"t_p95\": 31.0,\n",
        "#       \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.0,\n",
        "#       \"t_grad_mean\": 0.5, \"t_grad_std\": 0.2,\n",
        "#       \"t_diff_mean\": 0.1, \"t_diff_std\": 0.05,\n",
        "#       \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.05,\n",
        "#       \"gas_val\": 400.0, \"gas_delta\": 5.0, \"gas_vel\": 0.5,\n",
        "#       \"tproxy_val\": 32.0, \"tproxy_delta\": 1.0, \"tproxy_vel\": 0.2\n",
        "#     }\n",
        "#   },\n",
        "#   \"threshold\": 0.5\n",
        "# }\n",
        "# M2_FIRE = {\n",
        "#   \"data\": {\n",
        "#     \"features_dict\": {\n",
        "#       \"t_mean\": 105.0, \"t_std\": 15.0, \"t_max\": 160.0, \"t_p95\": 150.0,\n",
        "#       \"t_hot_area_pct\": 40.0, \"t_hot_largest_blob_pct\": 30.0,\n",
        "#       \"t_grad_mean\": 12.0, \"t_grad_std\": 6.0,\n",
        "#       \"t_diff_mean\": 8.0, \"t_diff_std\": 4.0,\n",
        "#       \"flow_mag_mean\": 5.0, \"flow_mag_std\": 2.0,\n",
        "#       \"gas_val\": 2500.0, \"gas_delta\": 600.0, \"gas_vel\": 600.0,\n",
        "#       \"tproxy_val\": 160.0, \"tproxy_delta\": 20.0, \"tproxy_vel\": 20.0\n",
        "#     }\n",
        "#   },\n",
        "#   \"threshold\": 0.5\n",
        "# }\n",
        "\n",
        "# # ---------- Prefills: Model 3 (Kaggle Base model) ----------\n",
        "# M3_NON_FIRE = {\n",
        "#   \"data\": {\n",
        "#     \"Temperature[C]\": 23.5, \"Humidity[%]\": 42, \"TVOC[ppb]\": 3, \"eCO2[ppm]\": 420,\n",
        "#     \"PM1.0\": 1.2, \"PM2.5\": 2.3, \"PM10\": 3.4, \"Pressure[hPa]\": 1013.2,\n",
        "#     \"Raw H2\": 14500, \"Raw Ethanol\": 21000, \"CNT\": 0, \"UTC\": 0,\n",
        "#     \"NC0.5\": 0, \"NC1.0\": 0, \"NC2.5\": 0\n",
        "#   }\n",
        "# }\n",
        "# M3_FIRE = {\n",
        "#   \"data\": {\n",
        "#     \"Temperature[C]\": 45.7, \"Humidity[%]\": 15.3, \"TVOC[ppb]\": 850, \"eCO2[ppm]\": 2200,\n",
        "#     \"PM1.0\": 80.1, \"PM2.5\": 120.5, \"PM10\": 155.0, \"Pressure[hPa]\": 1002.1,\n",
        "#     \"Raw H2\": 30000, \"Raw Ethanol\": 42000, \"CNT\": 123456, \"UTC\": 1623859200,\n",
        "#     \"NC0.5\": 3500, \"NC1.0\": 2100, \"NC2.5\": 1500\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# # ---------- Helpers ----------\n",
        "# def coerce_value(v: Any) -> Any:\n",
        "#     if isinstance(v, str):\n",
        "#         if v.strip() == \"\":\n",
        "#             return v\n",
        "#         try:\n",
        "#             if \".\" in v or \"e\" in v.lower():\n",
        "#                 return float(v)\n",
        "#             return int(v)\n",
        "#         except Exception:\n",
        "#             return v\n",
        "#     return v\n",
        "\n",
        "# def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
        "#     items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
        "#     return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
        "\n",
        "# def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "#     out = {}\n",
        "#     for _, row in df.iterrows():\n",
        "#         key = str(row.get(\"feature\", \"\")).strip()\n",
        "#         if not key:\n",
        "#             continue\n",
        "#         out[key] = coerce_value(row.get(\"value\"))\n",
        "#     return out\n",
        "\n",
        "# def post_json(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
        "#     r = requests.post(url, json=payload, timeout=timeout_s)\n",
        "#     r.raise_for_status()\n",
        "#     return r.json()\n",
        "\n",
        "# def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
        "#     st.markdown(\n",
        "#         f\"\"\"\n",
        "#         <div style=\"\n",
        "#             padding: 12px 14px; border-radius: 8px;\n",
        "#             background: {bg}; color: {color}; border: 1px solid {border};\n",
        "#             font-weight: 500;\">\n",
        "#             {text}\n",
        "#         </div>\n",
        "#         \"\"\", unsafe_allow_html=True\n",
        "#     )\n",
        "\n",
        "# def html_summary_table(rows, key_to_color=None):\n",
        "#     \"\"\"\n",
        "#     rows: List[Tuple[field, value]]\n",
        "#     key_to_color: dict like {\"Label\": (\"red\"|\"green\"|\"none\", condition_bool)} is ignored;\n",
        "#                   we color based on value semantics below.\n",
        "#     \"\"\"\n",
        "#     def cell_style(field, val):\n",
        "#         # Model 1: Label\n",
        "#         if field.lower() == \"label\":\n",
        "#             if isinstance(val, str) and val.strip().lower() == \"fire\":\n",
        "#                 return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
        "#             if isinstance(val, str) and val.strip().lower() == \"not fire\":\n",
        "#                 return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
        "#         # Model 2: fire_detected\n",
        "#         if field == \"fire_detected\":\n",
        "#             if val is True:\n",
        "#                 return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
        "#             if val is False:\n",
        "#                 return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
        "#         # Model 3: fire_prediction\n",
        "#         if field == \"fire_prediction\":\n",
        "#             if val is True:\n",
        "#                 return \"background:#fde8e8;color:#7a1111;font-weight:600;\"\n",
        "#             if val is False:\n",
        "#                 return \"background:#e6f4ea;color:#0b5b25;font-weight:600;\"\n",
        "#         return \"\"\n",
        "#     html = ['<table style=\"width:100%;border-collapse:collapse;\">']\n",
        "#     for field, val in rows:\n",
        "#         style = cell_style(field, val)\n",
        "#         html.append(\n",
        "#             f'<tr>'\n",
        "#             f'<td style=\"border:1px solid #ddd;padding:8px;width:35%;font-weight:600;background:#fafafa;\">{field}</td>'\n",
        "#             f'<td style=\"border:1px solid #ddd;padding:8px;{style}\">{val}</td>'\n",
        "#             f'</tr>'\n",
        "#         )\n",
        "#     html.append('</table>')\n",
        "#     st.markdown(\"\".join(html), unsafe_allow_html=True)\n",
        "\n",
        "# # ========================= Email Notification System =========================\n",
        "# # Session state for email deduplication\n",
        "# if 'last_fire_alerts' not in st.session_state:\n",
        "#     st.session_state.last_fire_alerts = {}\n",
        "\n",
        "# def should_send_alert(model_name: str, prediction_data: Dict[str, Any]) -> bool:\n",
        "#     \"\"\"Check if we should send an alert to avoid duplicates\"\"\"\n",
        "#     # Create a simple hash of the prediction data\n",
        "#     pred_hash = hash(str(sorted(prediction_data.items())))\n",
        "\n",
        "#     # Check if we've already sent an alert for this prediction\n",
        "#     last_alert = st.session_state.last_fire_alerts.get(model_name)\n",
        "#     if last_alert == pred_hash:\n",
        "#         return False\n",
        "\n",
        "#     # Update the last alert hash\n",
        "#     st.session_state.last_fire_alerts[model_name] = pred_hash\n",
        "#     return True\n",
        "\n",
        "# def send_fire_alert_email(model_name: str, prediction_data: Dict[str, Any], email_config: Dict[str, str]):\n",
        "#     \"\"\"Send an email alert when fire is detected\"\"\"\n",
        "#     try:\n",
        "#         # Create message\n",
        "#         msg = MIMEMultipart()\n",
        "#         msg['From'] = email_config['sender_email']\n",
        "#         msg['To'] = email_config['recipient_email']\n",
        "#         msg['Subject'] = f\"🔥 FIRE ALERT - {model_name} Detected Fire\"\n",
        "\n",
        "#         # Format prediction data for email\n",
        "#         prediction_str = \"\\n\".join([f\"{k}: {v}\" for k, v in prediction_data.items()])\n",
        "\n",
        "#         # Create email body\n",
        "#         body = f\"\"\"\n",
        "# FIRE DETECTED by {model_name}!\n",
        "\n",
        "# Prediction Details:\n",
        "# {prediction_str}\n",
        "\n",
        "# Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "# Please take immediate action.\n",
        "# \"\"\"\n",
        "\n",
        "#         msg.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "#         # Create SMTP session\n",
        "#         server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "#         server.starttls()\n",
        "#         server.login(email_config['sender_email'], email_config['sender_password'])\n",
        "\n",
        "#         # Send email\n",
        "#         text = msg.as_string()\n",
        "#         server.sendmail(email_config['sender_email'], email_config['recipient_email'], text)\n",
        "#         server.quit()\n",
        "\n",
        "#         return True\n",
        "#     except Exception as e:\n",
        "#         print(f\"Failed to send email: {e}\")\n",
        "#         return False\n",
        "\n",
        "# # ========================= UI =========================\n",
        "# st.title(\"🔥 Fire Prediction — Live data\")\n",
        "\n",
        "# # ========================= EMAIL CONFIGURATION =========================\n",
        "# st.sidebar.header(\"📧 Email Notifications\")\n",
        "# enable_email = st.sidebar.checkbox(\"Enable Email Alerts\", value=False)\n",
        "# sender_email = st.sidebar.text_input(\"Sender Email (Gmail)\", placeholder=\"your_email@gmail.com\")\n",
        "# sender_password = st.sidebar.text_input(\"App Password\", type=\"password\", placeholder=\"Gmail App Password\")\n",
        "# recipient_email = st.sidebar.text_input(\"Recipient Email\", value=\"ch.ajay1707@gmail.com\")\n",
        "\n",
        "# # Test email configuration\n",
        "# if st.sidebar.button(\"Test Email Configuration\"):\n",
        "#     if sender_email and sender_password and recipient_email:\n",
        "#         test_config = {\n",
        "#             'sender_email': sender_email,\n",
        "#             'sender_password': sender_password,\n",
        "#             'recipient_email': recipient_email\n",
        "#         }\n",
        "#         # Send test email\n",
        "#         test_data = {\"status\": \"Test email from Fire Prediction App\", \"result\": \"Configuration successful\"}\n",
        "#         email_sent = send_fire_alert_email(\"Test Notification\", test_data, test_config)\n",
        "#         if email_sent:\n",
        "#             st.sidebar.success(\"✅ Test email sent successfully!\")\n",
        "#         else:\n",
        "#             st.sidebar.error(\"❌ Failed to send test email. Check your configuration.\")\n",
        "#     else:\n",
        "#         st.sidebar.warning(\"Please fill in all email fields first.\")\n",
        "\n",
        "# st.sidebar.caption(\"Note: Use Gmail App Passwords for security. Enable 2FA and generate an app password.\")\n",
        "# st.sidebar.markdown(\"\"\"\n",
        "#     **Setup Instructions:**\n",
        "#     1. Enable 2-Factor Authentication on your Gmail account\n",
        "#     2. Generate an App Password in your Google Account settings\n",
        "#     3. Enter your Gmail address and App Password above\n",
        "#     4. Verify the recipient email is correct\n",
        "#     5. Click 'Test Email Configuration' to verify\n",
        "#     6. Enable email alerts\n",
        "# \"\"\")\n",
        "\n",
        "# # Store email config in session state\n",
        "# email_config = {\n",
        "#     'sender_email': sender_email,\n",
        "#     'sender_password': sender_password,\n",
        "#     'recipient_email': recipient_email\n",
        "# }\n",
        "\n",
        "# tabs = st.tabs([\"Live data fire prediction\", \"18 Features research data\", \"Kaggle Base model\"])\n",
        "\n",
        "# # ========================= Model 1 =========================\n",
        "# with tabs[0]:\n",
        "#     st.subheader(\"Fire prediction live data\")\n",
        "#     left, right = st.columns([1, 1])\n",
        "#     with left:\n",
        "#         m1_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m1_prefill\")\n",
        "#     with right:\n",
        "#         m1_url = st.text_input(\"Endpoint\", value=M1_URL, key=\"m1_endpoint\")\n",
        "\n",
        "#     # Session defaults\n",
        "#     if \"m1_frame\" not in st.session_state:\n",
        "#         st.session_state.m1_frame = M1_NON_FIRE[\"frame\"]\n",
        "#     if \"m1_timestamp\" not in st.session_state:\n",
        "#         st.session_state.m1_timestamp = M1_NON_FIRE[\"timestamp\"]\n",
        "#     if \"m1_threshold\" not in st.session_state:\n",
        "#         st.session_state.m1_threshold = M1_NON_FIRE[\"decision_threshold\"]\n",
        "#     if \"m1_table\" not in st.session_state:\n",
        "#         st.session_state.m1_table = df_from_features_dict(M1_NON_FIRE[\"features\"])\n",
        "\n",
        "#     # Prefill\n",
        "#     src1 = M1_NON_FIRE if m1_prefill == \"Non-Fire sample\" else M1_FIRE if m1_prefill == \"Fire sample\" else None\n",
        "#     if src1 is not None:\n",
        "#         st.session_state.m1_frame = src1[\"frame\"]\n",
        "#         st.session_state.m1_timestamp = src1[\"timestamp\"]\n",
        "#         st.session_state.m1_threshold = src1.get(\"decision_threshold\", 0.4)\n",
        "#         st.session_state.m1_table = df_from_features_dict(src1[\"features\"])\n",
        "\n",
        "#     st.markdown(\"**Metadata**\")\n",
        "#     c1, c2, c3 = st.columns([1, 1.2, 1])\n",
        "#     with c1:\n",
        "#         st.session_state.m1_frame = st.number_input(\"frame\", value=int(st.session_state.m1_frame), step=1, key=\"m1_frame_input\")\n",
        "#     with c2:\n",
        "#         st.session_state.m1_timestamp = st.text_input(\"timestamp (ISO 8601, Zulu)\", value=st.session_state.m1_timestamp, key=\"m1_ts_input\")\n",
        "#     with c3:\n",
        "#         st.session_state.m1_threshold = st.number_input(\"decision_threshold\", value=float(st.session_state.m1_threshold), step=0.05, format=\"%.4f\", key=\"m1_thr_input\")\n",
        "\n",
        "#     st.markdown(\"**Features (editable table)**\")\n",
        "#     st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
        "#     st.session_state.m1_table = st.data_editor(\n",
        "#         st.session_state.m1_table.copy(),\n",
        "#         num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m1_features_editor\"\n",
        "#     )\n",
        "\n",
        "#     m1_run = st.button(\"Prediction (Saafe model)\", type=\"primary\", use_container_width=True, key=\"m1_run_btn\")\n",
        "#     st.divider()\n",
        "\n",
        "#     if m1_run:\n",
        "#         try:\n",
        "#             payload1 = {\n",
        "#                 \"frame\": int(st.session_state.m1_frame),\n",
        "#                 \"timestamp\": st.session_state.m1_timestamp,\n",
        "#                 \"features\": features_dict_from_df(st.session_state.m1_table),\n",
        "#                 \"decision_threshold\": float(st.session_state.m1_threshold),\n",
        "#             }\n",
        "#             with st.spinner(\"Calling AWS Lambda...\"):\n",
        "#                 t0 = time.time()\n",
        "#                 resp1 = post_json(m1_url, payload1, timeout_s=25.0)\n",
        "#                 elapsed = time.time() - t0\n",
        "\n",
        "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "#             # Colored banner + summary table (Label cell colored)\n",
        "#             pred = resp1.get(\"prediction\", {}) or {}\n",
        "#             lbl = str(pred.get(\"label\", \"\")).lower()\n",
        "#             fire_detected = \"fire\" in lbl and \"not\" not in lbl\n",
        "\n",
        "#             if fire_detected:\n",
        "#                 colored_box(\"🔥 Fire detected by Saafe model\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "#                 # Send email alert if enabled and not a duplicate\n",
        "#                 if enable_email and sender_email and sender_password and recipient_email:\n",
        "#                     if should_send_alert(\"Saafe Model\", pred):\n",
        "#                         email_sent = send_fire_alert_email(\"Saafe Model\", pred, email_config)\n",
        "#                         if email_sent:\n",
        "#                             st.success(\"📧 Fire alert email sent successfully!\")\n",
        "#                         else:\n",
        "#                             st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "#                     else:\n",
        "#                         st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "#             else:\n",
        "#                 colored_box(\"✅ Not Fire (Saafe model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "#             st.subheader(\"Prediction Summary\")\n",
        "#             summary_rows = [\n",
        "#                 (\"Label\", str(pred.get(\"label\", \"—\"))),\n",
        "#                 (\"Fire probability\", f\"{pred.get('fire_probability'):.6f}\" if isinstance(pred.get(\"fire_probability\"), (int, float)) else str(pred.get(\"fire_probability\"))),\n",
        "#                 (\"Frame\", resp1.get(\"frame\", payload1[\"frame\"])),\n",
        "#                 (\"Timestamp\", resp1.get(\"timestamp\", payload1[\"timestamp\"])),\n",
        "#             ]\n",
        "#             html_summary_table(summary_rows)\n",
        "\n",
        "#             # Explanation tables — Local first, then Global\n",
        "#             expl = resp1.get(\"explanation\", {}) or {}\n",
        "#             lcontrib = expl.get(\"local_contributions\", [])\n",
        "#             gtf = expl.get(\"global_top_features\", [])\n",
        "\n",
        "#             if isinstance(lcontrib, list) and lcontrib:\n",
        "#                 st.subheader(\"Local Contributions\")\n",
        "#                 st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
        "\n",
        "#             if isinstance(gtf, list) and gtf:\n",
        "#                 st.subheader(\"Global Top Features\")\n",
        "#                 st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
        "\n",
        "#             notes = expl.get(\"notes\")\n",
        "#             if notes:\n",
        "#                 colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
        "\n",
        "#         except requests.HTTPError as e:\n",
        "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error: {e}\")\n",
        "\n",
        "# # ========================= Model 2 =========================\n",
        "# with tabs[1]:\n",
        "#     st.subheader(\"18 Features research data\")\n",
        "#     left, right = st.columns([1, 1])\n",
        "#     with left:\n",
        "#         m2_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m2_prefill\")\n",
        "#     with right:\n",
        "#         m2_url = st.text_input(\"Endpoint\", value=M2_URL, key=\"m2_endpoint\")\n",
        "\n",
        "#     if \"m2_threshold\" not in st.session_state:\n",
        "#         st.session_state.m2_threshold = float(M2_NON_FIRE[\"threshold\"])\n",
        "#     if \"m2_table\" not in st.session_state:\n",
        "#         st.session_state.m2_table = df_from_features_dict(M2_NON_FIRE[\"data\"][\"features_dict\"])\n",
        "\n",
        "#     src2 = M2_NON_FIRE if m2_prefill == \"Non-Fire sample\" else M2_FIRE if m2_prefill == \"Fire sample\" else None\n",
        "#     if src2 is not None:\n",
        "#         st.session_state.m2_threshold = float(src2.get(\"threshold\", 0.5))\n",
        "#         st.session_state.m2_table = df_from_features_dict(src2[\"data\"][\"features_dict\"])\n",
        "\n",
        "#     st.markdown(\"**Threshold**\")\n",
        "#     st.session_state.m2_threshold = st.number_input(\"threshold\", value=float(st.session_state.m2_threshold), step=0.05, format=\"%.2f\", key=\"m2_thr_input\")\n",
        "\n",
        "#     st.markdown(\"**Features (editable table)**\")\n",
        "#     st.caption(\"Exactly 18 core features expected by this API.\")\n",
        "#     st.session_state.m2_table = st.data_editor(\n",
        "#         st.session_state.m2_table.copy(),\n",
        "#         num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m2_features_editor\"\n",
        "#     )\n",
        "\n",
        "#     m2_run = st.button(\"Prediction (18 Features)\", type=\"primary\", use_container_width=True, key=\"m2_run_btn\")\n",
        "#     st.divider()\n",
        "\n",
        "#     if m2_run:\n",
        "#         try:\n",
        "#             payload2 = {\n",
        "#                 \"data\": {\"features_dict\": features_dict_from_df(st.session_state.m2_table)},\n",
        "#                 \"threshold\": float(st.session_state.m2_threshold),\n",
        "#             }\n",
        "#             with st.spinner(\"Calling 18-Features API...\"):\n",
        "#                 t0 = time.time()\n",
        "#                 resp2 = post_json(m2_url, payload2, timeout_s=25.0)\n",
        "#                 elapsed = time.time() - t0\n",
        "\n",
        "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "#             # Banner FIRST (as requested)\n",
        "#             fire_detected = bool(resp2.get(\"fire_detected\", False))\n",
        "#             if fire_detected:\n",
        "#                 colored_box(\"🔥 Fire detected (18 Features)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "#                 # Send email alert if enabled and not a duplicate\n",
        "#                 if enable_email and sender_email and sender_password and recipient_email:\n",
        "#                     if should_send_alert(\"18 Features Model\", resp2):\n",
        "#                         email_sent = send_fire_alert_email(\"18 Features Model\", resp2, email_config)\n",
        "#                         if email_sent:\n",
        "#                             st.success(\"📧 Fire alert email sent successfully!\")\n",
        "#                         else:\n",
        "#                             st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "#                     else:\n",
        "#                         st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "#             else:\n",
        "#                 colored_box(\"✅ Not Fire (18 Features)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "#             # Summary table with colored fire_detected cell\n",
        "#             st.subheader(\"Prediction Summary\")\n",
        "#             rows = [\n",
        "#                 (\"fire_detected\", bool(resp2.get(\"fire_detected\", False))),\n",
        "#                 (\"score\", f\"{resp2.get('score'):.6f}\" if isinstance(resp2.get(\"score\"), (int, float)) else str(resp2.get(\"score\"))),\n",
        "#                 (\"latency_ms\", f\"{resp2.get('latency_ms'):.3f}\" if isinstance(resp2.get(\"latency_ms\"), (int, float)) else str(resp2.get(\"latency_ms\"))),\n",
        "#             ]\n",
        "#             html_summary_table(rows)\n",
        "\n",
        "#         except requests.HTTPError as e:\n",
        "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error: {e}\")\n",
        "\n",
        "# # ========================= Model 3 =========================\n",
        "# with tabs[2]:\n",
        "#     st.subheader(\"Kaggle Base model\")\n",
        "#     left, right = st.columns([1, 1])\n",
        "#     with left:\n",
        "#         m3_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m3_prefill\")\n",
        "#     with right:\n",
        "#         m3_url = st.text_input(\"Endpoint\", value=M3_URL, key=\"m3_endpoint\")\n",
        "\n",
        "#     if \"m3_table\" not in st.session_state:\n",
        "#         st.session_state.m3_table = df_from_features_dict(M3_NON_FIRE[\"data\"])\n",
        "\n",
        "#     # Prefill\n",
        "#     src3 = M3_NON_FIRE if m3_prefill == \"Non-Fire sample\" else M3_FIRE if m3_prefill == \"Fire sample\" else None\n",
        "#     if src3 is not None:\n",
        "#         st.session_state.m3_table = df_from_features_dict(src3[\"data\"])\n",
        "\n",
        "#     st.markdown(\"**Features (editable table)**\")\n",
        "#     st.caption(\"Kaggle Base model sensor set.\")\n",
        "#     st.session_state.m3_table = st.data_editor(\n",
        "#         st.session_state.m3_table.copy(),\n",
        "#         num_rows=\"dynamic\", use_container_width=True, hide_index=True, key=\"m3_features_editor\"\n",
        "#     )\n",
        "\n",
        "#     m3_run = st.button(\"Prediction (Kaggle Base)\", type=\"primary\", use_container_width=True, key=\"m3_run_btn\")\n",
        "#     st.divider()\n",
        "\n",
        "#     if m3_run:\n",
        "#         try:\n",
        "#             payload3 = {\"data\": features_dict_from_df(st.session_state.m3_table)}\n",
        "#             with st.spinner(\"Calling Kaggle Base API...\"):\n",
        "#                 t0 = time.time()\n",
        "#                 resp3 = post_json(m3_url, payload3, timeout_s=25.0)\n",
        "#                 elapsed = time.time() - t0\n",
        "\n",
        "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "#             # Banner FIRST (as requested)\n",
        "#             fire_detected = bool(resp3.get(\"fire_prediction\", False))\n",
        "#             if fire_detected:\n",
        "#                 colored_box(\"🔥 Fire detected (Kaggle Base model)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "#                 # Send email alert if enabled and not a duplicate\n",
        "#                 if enable_email and sender_email and sender_password and recipient_email:\n",
        "#                     if should_send_alert(\"Kaggle Base Model\", resp3):\n",
        "#                         email_sent = send_fire_alert_email(\"Kaggle Base Model\", resp3, email_config)\n",
        "#                         if email_sent:\n",
        "#                             st.success(\"📧 Fire alert email sent successfully!\")\n",
        "#                         else:\n",
        "#                             st.error(\"📧 Failed to send fire alert email. Check your email configuration.\")\n",
        "#                     else:\n",
        "#                         st.info(\"📧 Fire detected but email alert was already sent for this prediction.\")\n",
        "#             else:\n",
        "#                 colored_box(\"✅ Not Fire (Kaggle Base model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "#             # Summary table with colored fire_prediction cell\n",
        "#             st.subheader(\"Prediction Summary\")\n",
        "#             rows = [\n",
        "#                 (\"fire_prediction\", bool(resp3.get(\"fire_prediction\", False))),\n",
        "#                 (\"score\", f\"{resp3.get('score'):.12f}\" if isinstance(resp3.get(\"score\"), (int, float)) else str(resp3.get(\"score\"))),\n",
        "#                 (\"latency_ms\", f\"{resp3.get('latency_ms'):.3f}\" if isinstance(resp3.get(\"latency_ms\"), (int, float)) else str(resp3.get(\"latency_ms\"))),\n",
        "#             ]\n",
        "#             html_summary_table(rows)\n",
        "\n",
        "#         except requests.HTTPError as e:\n",
        "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc69MVXleeXu"
      },
      "source": [
        " 2 Model testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUNiUWtMbS7e"
      },
      "outputs": [],
      "source": [
        "# %%writefile app.py\n",
        "# import time\n",
        "# from typing import Any, Dict\n",
        "\n",
        "# import pandas as pd\n",
        "# import requests\n",
        "# import streamlit as st\n",
        "\n",
        "# st.set_page_config(page_title=\"Fire Prediction (2 Models)\", page_icon=\"🔥\", layout=\"wide\")\n",
        "\n",
        "# # ---- Endpoints ----\n",
        "# LAMBDA_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
        "# APP_RUNNER_URL = \"https://rnmsxp5s53.us-east-1.awsapprunner.com/predict_features\"\n",
        "\n",
        "# # ---------- Samples: Model 1 (Full model, many features) ----------\n",
        "# M1_NON_FIRE = {\n",
        "#   \"frame\": 5678,\n",
        "#   \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
        "#   \"features\": {\n",
        "#     \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
        "#     \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
        "#     \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
        "#     \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
        "#     \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
        "\n",
        "#     \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
        "#     \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
        "#     \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
        "#     \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
        "\n",
        "#     \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
        "#     \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
        "#     \"spike_count_voc_2m\": 0,\n",
        "\n",
        "#     \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
        "#     \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
        "#     \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
        "\n",
        "#     \"is_weekend\": 0, \"asleep_window\": 0,\n",
        "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
        "#   },\n",
        "#   \"decision_threshold\": 0.4\n",
        "# }\n",
        "\n",
        "# M1_FIRE = {\n",
        "#   \"frame\": 1234,\n",
        "#   \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
        "#   \"features\": {\n",
        "#     \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
        "#     \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
        "#     \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
        "#     \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
        "#     \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
        "#     \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
        "#     \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
        "#     \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
        "#     \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
        "#     \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
        "#     \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
        "#     \"spike_count_voc_2m\": 4,\n",
        "#     \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
        "#     \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
        "#     \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
        "#     \"is_weekend\": 0, \"asleep_window\": 1,\n",
        "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
        "#   },\n",
        "#   \"decision_threshold\": 0.4\n",
        "# }\n",
        "\n",
        "# # ---------- Samples: Model 2 (18 Features research data) ----------\n",
        "# M2_NON_FIRE = {\n",
        "#   \"data\": {\n",
        "#     \"features_dict\": {\n",
        "#       \"t_mean\": 28.0, \"t_std\": 2.0, \"t_max\": 32.0, \"t_p95\": 31.0,\n",
        "#       \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.0,\n",
        "#       \"t_grad_mean\": 0.5, \"t_grad_std\": 0.2,\n",
        "#       \"t_diff_mean\": 0.1, \"t_diff_std\": 0.05,\n",
        "#       \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.05,\n",
        "#       \"gas_val\": 400.0, \"gas_delta\": 5.0, \"gas_vel\": 0.5,\n",
        "#       \"tproxy_val\": 32.0, \"tproxy_delta\": 1.0, \"tproxy_vel\": 0.2\n",
        "#     }\n",
        "#   },\n",
        "#   \"threshold\": 0.5\n",
        "# }\n",
        "\n",
        "# M2_FIRE = {\n",
        "#   \"data\": {\n",
        "#     \"features_dict\": {\n",
        "#       \"t_mean\": 105.0, \"t_std\": 15.0, \"t_max\": 160.0, \"t_p95\": 150.0,\n",
        "#       \"t_hot_area_pct\": 40.0, \"t_hot_largest_blob_pct\": 30.0,\n",
        "#       \"t_grad_mean\": 12.0, \"t_grad_std\": 6.0,\n",
        "#       \"t_diff_mean\": 8.0, \"t_diff_std\": 4.0,\n",
        "#       \"flow_mag_mean\": 5.0, \"flow_mag_std\": 2.0,\n",
        "#       \"gas_val\": 2500.0, \"gas_delta\": 600.0, \"gas_vel\": 600.0,\n",
        "#       \"tproxy_val\": 160.0, \"tproxy_delta\": 20.0, \"tproxy_vel\": 20.0\n",
        "#     }\n",
        "#   },\n",
        "#   \"threshold\": 0.5\n",
        "# }\n",
        "\n",
        "# # ---------- Helpers ----------\n",
        "# def coerce_value(v: Any) -> Any:\n",
        "#     if isinstance(v, str):\n",
        "#         if v.strip() == \"\":\n",
        "#             return v\n",
        "#         try:\n",
        "#             if \".\" in v or \"e\" in v.lower():\n",
        "#                 return float(v)\n",
        "#             return int(v)\n",
        "#         except Exception:\n",
        "#             return v\n",
        "#     return v\n",
        "\n",
        "# def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
        "#     items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
        "#     return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
        "\n",
        "# def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "#     out = {}\n",
        "#     for _, row in df.iterrows():\n",
        "#         key = str(row.get(\"feature\", \"\")).strip()\n",
        "#         if not key:\n",
        "#             continue\n",
        "#         out[key] = coerce_value(row.get(\"value\"))\n",
        "#     return out\n",
        "\n",
        "# def post_json(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
        "#     r = requests.post(url, json=payload, timeout=timeout_s)\n",
        "#     r.raise_for_status()\n",
        "#     return r.json()\n",
        "\n",
        "# def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
        "#     st.markdown(\n",
        "#         f\"\"\"\n",
        "#         <div style=\"\n",
        "#             padding: 12px 14px;\n",
        "#             border-radius: 8px;\n",
        "#             background: {bg};\n",
        "#             color: {color};\n",
        "#             border: 1px solid {border};\n",
        "#             font-weight: 500;\">\n",
        "#             {text}\n",
        "#         </div>\n",
        "#         \"\"\",\n",
        "#         unsafe_allow_html=True\n",
        "#     )\n",
        "\n",
        "# # ========================= UI =========================\n",
        "# st.title(\"🔥 Fire Prediction — Table Only (Two Models)\")\n",
        "# tabs = st.tabs([\"Full model (AWS Lambda)\", \"18 Features research data\"])\n",
        "\n",
        "# # ========================= Model 1 =========================\n",
        "# with tabs[0]:\n",
        "#     st.subheader(\"Full model (AWS Lambda)\")\n",
        "#     left, right = st.columns([1, 1])\n",
        "#     with left:\n",
        "#         m1_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m1_prefill\")\n",
        "#     with right:\n",
        "#         lambda_url = st.text_input(\"Endpoint\", value=LAMBDA_URL, key=\"m1_endpoint\")\n",
        "\n",
        "#     # Session defaults for Model 1\n",
        "#     if \"m1_frame\" not in st.session_state:\n",
        "#         st.session_state.m1_frame = M1_NON_FIRE[\"frame\"]\n",
        "#     if \"m1_timestamp\" not in st.session_state:\n",
        "#         st.session_state.m1_timestamp = M1_NON_FIRE[\"timestamp\"]\n",
        "#     if \"m1_threshold\" not in st.session_state:\n",
        "#         st.session_state.m1_threshold = M1_NON_FIRE[\"decision_threshold\"]\n",
        "#     if \"m1_table\" not in st.session_state:\n",
        "#         st.session_state.m1_table = df_from_features_dict(M1_NON_FIRE[\"features\"])\n",
        "\n",
        "#     # Apply prefill\n",
        "#     src1 = M1_NON_FIRE if m1_prefill == \"Non-Fire sample\" else M1_FIRE if m1_prefill == \"Fire sample\" else None\n",
        "#     if src1 is not None:\n",
        "#         st.session_state.m1_frame = src1[\"frame\"]\n",
        "#         st.session_state.m1_timestamp = src1[\"timestamp\"]\n",
        "#         st.session_state.m1_threshold = src1.get(\"decision_threshold\", 0.4)\n",
        "#         st.session_state.m1_table = df_from_features_dict(src1[\"features\"])\n",
        "\n",
        "#     st.markdown(\"**Metadata**\")\n",
        "#     c1, c2, c3 = st.columns([1, 1.2, 1])\n",
        "#     with c1:\n",
        "#         st.session_state.m1_frame = st.number_input(\"frame\", value=int(st.session_state.m1_frame), step=1, key=\"m1_frame_input\")\n",
        "#     with c2:\n",
        "#         st.session_state.m1_timestamp = st.text_input(\"timestamp (ISO 8601, Zulu)\", value=st.session_state.m1_timestamp, key=\"m1_ts_input\")\n",
        "#     with c3:\n",
        "#         st.session_state.m1_threshold = st.number_input(\"decision_threshold\", value=float(st.session_state.m1_threshold), step=0.05, format=\"%.4f\", key=\"m1_thr_input\")\n",
        "\n",
        "#     st.markdown(\"**Features (editable table)**\")\n",
        "#     st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
        "#     st.session_state.m1_table = st.data_editor(\n",
        "#         st.session_state.m1_table.copy(),\n",
        "#         num_rows=\"dynamic\",\n",
        "#         use_container_width=True,\n",
        "#         hide_index=True,\n",
        "#         key=\"m1_features_editor\"\n",
        "#     )\n",
        "\n",
        "#     m1_run = st.button(\"Prediction (Full model)\", type=\"primary\", use_container_width=True, key=\"m1_run_btn\")\n",
        "#     st.divider()\n",
        "\n",
        "#     if m1_run:\n",
        "#         try:\n",
        "#             payload1 = {\n",
        "#                 \"frame\": int(st.session_state.m1_frame),\n",
        "#                 \"timestamp\": st.session_state.m1_timestamp,\n",
        "#                 \"features\": features_dict_from_df(st.session_state.m1_table),\n",
        "#                 \"decision_threshold\": float(st.session_state.m1_threshold),\n",
        "#             }\n",
        "#             with st.spinner(\"Calling AWS Lambda...\"):\n",
        "#                 t0 = time.time()\n",
        "#                 resp1 = post_json(lambda_url, payload1, timeout_s=25.0)\n",
        "#                 elapsed = time.time() - t0\n",
        "\n",
        "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "#             # Build a small summary table (no raw JSON)\n",
        "#             pred = resp1.get(\"prediction\", {}) or {}\n",
        "#             summary_rows = [\n",
        "#                 [\"Label\", str(pred.get(\"label\", \"—\"))],\n",
        "#                 [\"Fire probability\", f\"{pred.get('fire_probability'):.6f}\" if isinstance(pred.get(\"fire_probability\"), (int, float)) else str(pred.get(\"fire_probability\"))],\n",
        "#                 [\"Frame\", resp1.get(\"frame\", payload1[\"frame\"])],\n",
        "#                 [\"Timestamp\", resp1.get(\"timestamp\", payload1[\"timestamp\"])],\n",
        "#             ]\n",
        "#             st.subheader(\"Prediction Summary\")\n",
        "#             st.dataframe(pd.DataFrame(summary_rows, columns=[\"Field\", \"Value\"]), use_container_width=True)\n",
        "\n",
        "#             # Colored banner\n",
        "#             lbl = str(pred.get(\"label\", \"\")).lower()\n",
        "#             if \"fire\" in lbl and \"not\" not in lbl:\n",
        "#                 colored_box(\"🔥 Fire detected by Full model\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "#             else:\n",
        "#                 colored_box(\"✅ Not Fire (Full model)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "#             # Explanation tables (Local first, then Global)\n",
        "#             expl = resp1.get(\"explanation\", {}) or {}\n",
        "#             lcontrib = expl.get(\"local_contributions\", [])\n",
        "#             gtf = expl.get(\"global_top_features\", [])\n",
        "\n",
        "#             if isinstance(lcontrib, list) and lcontrib:\n",
        "#                 st.subheader(\"Local Contributions\")\n",
        "#                 st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
        "\n",
        "#             if isinstance(gtf, list) and gtf:\n",
        "#                 st.subheader(\"Global Top Features\")\n",
        "#                 st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
        "\n",
        "#             notes = expl.get(\"notes\")\n",
        "#             if notes:\n",
        "#                 colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
        "\n",
        "#         except requests.HTTPError as e:\n",
        "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error: {e}\")\n",
        "\n",
        "# # ========================= Model 2 =========================\n",
        "# with tabs[1]:\n",
        "#     st.subheader(\"18 Features research data\")\n",
        "#     left, right = st.columns([1, 1])\n",
        "#     with left:\n",
        "#         m2_prefill = st.selectbox(\"Prefill\", [\"None\", \"Non-Fire sample\", \"Fire sample\"], index=1, key=\"m2_prefill\")\n",
        "#     with right:\n",
        "#         app_runner_url = st.text_input(\"Endpoint\", value=APP_RUNNER_URL, key=\"m2_endpoint\")\n",
        "\n",
        "#     # Session defaults for Model 2\n",
        "#     if \"m2_threshold\" not in st.session_state:\n",
        "#         st.session_state.m2_threshold = float(M2_NON_FIRE[\"threshold\"])\n",
        "#     if \"m2_table\" not in st.session_state:\n",
        "#         st.session_state.m2_table = df_from_features_dict(M2_NON_FIRE[\"data\"][\"features_dict\"])\n",
        "\n",
        "#     # Apply prefill\n",
        "#     src2 = M2_NON_FIRE if m2_prefill == \"Non-Fire sample\" else M2_FIRE if m2_prefill == \"Fire sample\" else None\n",
        "#     if src2 is not None:\n",
        "#         st.session_state.m2_threshold = float(src2.get(\"threshold\", 0.5))\n",
        "#         st.session_state.m2_table = df_from_features_dict(src2[\"data\"][\"features_dict\"])\n",
        "\n",
        "#     st.markdown(\"**Threshold**\")\n",
        "#     st.session_state.m2_threshold = st.number_input(\"threshold\", value=float(st.session_state.m2_threshold), step=0.05, format=\"%.2f\", key=\"m2_thr_input\")\n",
        "\n",
        "#     st.markdown(\"**Features (editable table)**\")\n",
        "#     st.caption(\"Exactly 18 core features expected in this research API. You can edit values below.\")\n",
        "#     st.session_state.m2_table = st.data_editor(\n",
        "#         st.session_state.m2_table.copy(),\n",
        "#         num_rows=\"dynamic\",\n",
        "#         use_container_width=True,\n",
        "#         hide_index=True,\n",
        "#         key=\"m2_features_editor\"\n",
        "#     )\n",
        "\n",
        "#     m2_run = st.button(\"Prediction (18 Features)\", type=\"primary\", use_container_width=True, key=\"m2_run_btn\")\n",
        "#     st.divider()\n",
        "\n",
        "#     if m2_run:\n",
        "#         try:\n",
        "#             payload2 = {\n",
        "#                 \"data\": {\"features_dict\": features_dict_from_df(st.session_state.m2_table)},\n",
        "#                 \"threshold\": float(st.session_state.m2_threshold),\n",
        "#             }\n",
        "#             with st.spinner(\"Calling 18-Features API...\"):\n",
        "#                 t0 = time.time()\n",
        "#                 resp2 = post_json(app_runner_url, payload2, timeout_s=25.0)\n",
        "#                 elapsed = time.time() - t0\n",
        "\n",
        "#             st.success(f\"Response OK ({elapsed:.2f}s)\")\n",
        "\n",
        "#             # Expecting: {\"fire_detected\": bool, \"score\": float, \"latency_ms\": float}\n",
        "#             # Render strictly as a table (no raw JSON)\n",
        "#             rows = [\n",
        "#                 [\"fire_detected\", resp2.get(\"fire_detected\", \"—\")],\n",
        "#                 [\"score\", f\"{resp2.get('score'):.6f}\" if isinstance(resp2.get(\"score\"), (int, float)) else str(resp2.get(\"score\"))],\n",
        "#                 [\"latency_ms\", f\"{resp2.get('latency_ms'):.3f}\" if isinstance(resp2.get(\"latency_ms\"), (int, float)) else str(resp2.get(\"latency_ms\"))],\n",
        "#             ]\n",
        "#             st.subheader(\"Prediction Summary\")\n",
        "#             st.dataframe(pd.DataFrame(rows, columns=[\"Field\", \"Value\"]), use_container_width=True)\n",
        "\n",
        "#             # Colored banner\n",
        "#             if bool(resp2.get(\"fire_detected\", False)):\n",
        "#                 colored_box(\"🔥 Fire detected (18 Features)\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "#             else:\n",
        "#                 colored_box(\"✅ Not Fire (18 Features)\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "#         except requests.HTTPError as e:\n",
        "#             st.error(f\"HTTP error: {e}\\n{getattr(e, 'response', None) and e.response.text}\")\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKYRiUrobIds"
      },
      "source": [
        "Live data app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEdFX5viVqgI"
      },
      "outputs": [],
      "source": [
        "# %%writefile app.py\n",
        "# import json\n",
        "# import time\n",
        "# from typing import Any, Dict\n",
        "\n",
        "# import pandas as pd\n",
        "# import requests\n",
        "# import streamlit as st\n",
        "\n",
        "# st.set_page_config(page_title=\"Fire Prediction (Live data)\", page_icon=\"🔥\", layout=\"wide\")\n",
        "\n",
        "# DEFAULT_LAMBDA_URL = \"https://cz6vmkmp6tnrkhojlpb3xsfw6i0icyqd.lambda-url.us-east-1.on.aws/\"\n",
        "\n",
        "# # ---------- Samples ----------\n",
        "# NON_FIRE_SAMPLE = {\n",
        "#   \"frame\": 5678,\n",
        "#   \"timestamp\": \"2025-09-08T12:45:00Z\",\n",
        "#   \"features\": {\n",
        "#     \"t_mean\": 24.0, \"t_std\": 0.5, \"t_max\": 28.0, \"t_p95\": 27.5,\n",
        "#     \"t_hot_area_pct\": 0.2, \"t_hot_largest_blob_pct\": 0.1,\n",
        "#     \"t_grad_mean\": 0.05, \"t_grad_std\": 0.02, \"t_diff_mean\": 0.03, \"t_diff_std\": 0.01,\n",
        "#     \"flow_mag_mean\": 0.1, \"flow_mag_std\": 0.01,\n",
        "#     \"tproxy_val\": 28.0, \"tproxy_delta\": 0.2, \"tproxy_vel\": 0.05,\n",
        "\n",
        "#     \"CO\": 0.2, \"VOC\": 0.5, \"NO2\": 0.01,\n",
        "#     \"CO_diff\": 0.02, \"VOC_diff\": 0.03, \"NO2_diff\": 0.0,\n",
        "#     \"VOC_ma5\": 0.4, \"CO_ma5\": 0.15, \"NO2_ma5\": 0.01,\n",
        "#     \"VOC_z\": 0.1, \"CO_z\": 0.1, \"NO2_z\": 0.0,\n",
        "\n",
        "#     \"temp_rise_c_per_min\": 0.2, \"temp_slope_30s\": 0.1,\n",
        "#     \"gas_var_30s\": 0.05, \"delta_temp_30s\": 0.2, \"delta_gas_10s\": 0.01,\n",
        "#     \"spike_count_voc_2m\": 0,\n",
        "\n",
        "#     \"temp_co_corr_lag_0s\": 0.10, \"temp_co_corr_lag_15s\": 0.08, \"temp_co_corr_lag_60s\": 0.05,\n",
        "#     \"temp_voc_corr_lag_0s\": 0.12, \"temp_voc_corr_lag_15s\": 0.10, \"temp_voc_corr_lag_60s\": 0.08,\n",
        "#     \"temp_co_xcorr_max_abs\": 0.15, \"temp_voc_xcorr_max_abs\": 0.18,\n",
        "\n",
        "#     \"is_weekend\": 0, \"asleep_window\": 0,\n",
        "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 0, \"hrblk_5\": 0\n",
        "#   },\n",
        "#   \"decision_threshold\": 0.4\n",
        "# }\n",
        "\n",
        "# FIRE_SAMPLE = {\n",
        "#   \"frame\": 1234,\n",
        "#   \"timestamp\": \"2025-09-08T12:34:56Z\",\n",
        "#   \"features\": {\n",
        "#     \"t_mean\": 28.12, \"t_std\": 0.83, \"t_max\": 74.56, \"t_p95\": 71.92,\n",
        "#     \"t_hot_area_pct\": 8.20, \"t_hot_largest_blob_pct\": 5.47,\n",
        "#     \"t_grad_mean\": 0.42, \"t_grad_std\": 0.25, \"t_diff_mean\": 0.18, \"t_diff_std\": 0.09,\n",
        "#     \"flow_mag_mean\": 0.50, \"flow_mag_std\": 0.05,\n",
        "#     \"tproxy_val\": 74.56, \"tproxy_delta\": 1.32, \"tproxy_vel\": 0.87,\n",
        "#     \"CO\": 0.9, \"VOC\": 2.5, \"NO2\": 0.03,\n",
        "#     \"CO_diff\": 0.30, \"VOC_diff\": 0.40, \"NO2_diff\": -0.01,\n",
        "#     \"VOC_ma5\": 2.10, \"CO_ma5\": 0.75, \"NO2_ma5\": 0.02,\n",
        "#     \"VOC_z\": 2.2, \"CO_z\": 1.1, \"NO2_z\": -0.2,\n",
        "#     \"temp_rise_c_per_min\": 12.5, \"temp_slope_30s\": 3.2,\n",
        "#     \"gas_var_30s\": 0.45, \"delta_temp_30s\": 8.7, \"delta_gas_10s\": 0.6,\n",
        "#     \"spike_count_voc_2m\": 4,\n",
        "#     \"temp_co_corr_lag_0s\": 0.72, \"temp_co_corr_lag_15s\": 0.68, \"temp_co_corr_lag_60s\": 0.55,\n",
        "#     \"temp_voc_corr_lag_0s\": 0.81, \"temp_voc_corr_lag_15s\": 0.77, \"temp_voc_corr_lag_60s\": 0.60,\n",
        "#     \"temp_co_xcorr_max_abs\": 0.74, \"temp_voc_xcorr_max_abs\": 0.83,\n",
        "#     \"is_weekend\": 0, \"asleep_window\": 1,\n",
        "#     \"hrblk_0\": 0, \"hrblk_1\": 0, \"hrblk_2\": 0, \"hrblk_3\": 0, \"hrblk_4\": 1, \"hrblk_5\": 0\n",
        "#   },\n",
        "#   \"decision_threshold\": 0.4\n",
        "# }\n",
        "\n",
        "# # ---------- Helpers ----------\n",
        "# def coerce_value(v: Any) -> Any:\n",
        "#     if isinstance(v, str):\n",
        "#         if v.strip() == \"\":\n",
        "#             return v\n",
        "#         try:\n",
        "#             if \".\" in v or \"e\" in v.lower():\n",
        "#                 return float(v)\n",
        "#             return int(v)\n",
        "#         except Exception:\n",
        "#             return v\n",
        "#     return v\n",
        "\n",
        "# def features_dict_from_df(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "#     out = {}\n",
        "#     for _, row in df.iterrows():\n",
        "#         key = str(row.get(\"feature\", \"\")).strip()\n",
        "#         if not key:\n",
        "#             continue\n",
        "#         out[key] = coerce_value(row.get(\"value\"))\n",
        "#     return out\n",
        "\n",
        "# def df_from_features_dict(feats: Dict[str, Any]) -> pd.DataFrame:\n",
        "#     items = sorted(feats.items(), key=lambda kv: kv[0].lower())\n",
        "#     return pd.DataFrame([{\"feature\": k, \"value\": v} for k, v in items])\n",
        "\n",
        "# def call_lambda(url: str, payload: Dict[str, Any], timeout_s: float = 25.0) -> Dict[str, Any]:\n",
        "#     headers = {\"Content-Type\": \"application/json\"}\n",
        "#     r = requests.post(url, headers=headers, json=payload, timeout=timeout_s)\n",
        "#     r.raise_for_status()\n",
        "#     return r.json()\n",
        "\n",
        "# def colored_box(text: str, bg: str, border: str = \"#00000020\", color: str = \"#111\"):\n",
        "#     st.markdown(\n",
        "#         f\"\"\"\n",
        "#         <div style=\"\n",
        "#             padding: 12px 14px;\n",
        "#             border-radius: 8px;\n",
        "#             background: {bg};\n",
        "#             color: {color};\n",
        "#             border: 1px solid {border};\n",
        "#             font-weight: 500;\">\n",
        "#             {text}\n",
        "#         </div>\n",
        "#         \"\"\",\n",
        "#         unsafe_allow_html=True\n",
        "#     )\n",
        "\n",
        "# # ---------- Sidebar ----------\n",
        "# st.sidebar.header(\"Settings\")\n",
        "# lambda_url = st.sidebar.text_input(\"AWS Lambda URL\", value=DEFAULT_LAMBDA_URL)\n",
        "# prefill = st.sidebar.selectbox(\n",
        "#     \"Prefill options\",\n",
        "#     options=[\"None\", \"Non-Fire sample\", \"Fire sample\"],\n",
        "#     index=1  # default to Non-Fire\n",
        "# )\n",
        "# st.sidebar.caption(\"Pick a prefill to load the table. You can then edit any cells or add/remove rows.\")\n",
        "\n",
        "# # ---------- Title ----------\n",
        "# st.title(\"🔥 Fire Prediction — Live Sensor Data\")\n",
        "# st.write(\"Edit the fields below and click **Prediction**. No JSON required.\")\n",
        "\n",
        "# # ---------- Session state init ----------\n",
        "# if \"table_df\" not in st.session_state:\n",
        "#     st.session_state.table_df = df_from_features_dict(NON_FIRE_SAMPLE[\"features\"])\n",
        "# if \"frame\" not in st.session_state:\n",
        "#     st.session_state.frame = NON_FIRE_SAMPLE[\"frame\"]\n",
        "# if \"timestamp\" not in st.session_state:\n",
        "#     st.session_state.timestamp = NON_FIRE_SAMPLE[\"timestamp\"]\n",
        "# if \"decision_threshold\" not in st.session_state:\n",
        "#     st.session_state.decision_threshold = NON_FIRE_SAMPLE[\"decision_threshold\"]\n",
        "\n",
        "# # ---------- Prefill logic (syncs table + metadata immediately) ----------\n",
        "# if prefill == \"Non-Fire sample\":\n",
        "#     src = NON_FIRE_SAMPLE\n",
        "# elif prefill == \"Fire sample\":\n",
        "#     src = FIRE_SAMPLE\n",
        "# else:\n",
        "#     src = None\n",
        "\n",
        "# if src is not None:\n",
        "#     st.session_state.table_df = df_from_features_dict(src[\"features\"])\n",
        "#     st.session_state.frame = src[\"frame\"]\n",
        "#     st.session_state.timestamp = src[\"timestamp\"]\n",
        "#     st.session_state.decision_threshold = src.get(\"decision_threshold\", 0.4)\n",
        "\n",
        "# # ---------- Table-only Input ----------\n",
        "# st.subheader(\"Metadata\")\n",
        "# c1, c2, c3 = st.columns([1, 1.2, 1])\n",
        "# with c1:\n",
        "#     st.session_state.frame = st.number_input(\"frame\", value=int(st.session_state.frame), step=1)\n",
        "# with c2:\n",
        "#     st.session_state.timestamp = st.text_input(\n",
        "#         \"timestamp (ISO 8601, Zulu)\",\n",
        "#         value=st.session_state.timestamp,\n",
        "#         help=\"Example: 2025-09-08T12:45:00Z\",\n",
        "#     )\n",
        "# with c3:\n",
        "#     st.session_state.decision_threshold = st.number_input(\n",
        "#         \"decision_threshold\", value=float(st.session_state.decision_threshold), step=0.05, format=\"%.4f\"\n",
        "#     )\n",
        "\n",
        "# st.subheader(\"Features (editable table)\")\n",
        "# st.caption(\"Edit feature names and values. Add/remove rows as needed.\")\n",
        "# st.session_state.table_df = st.data_editor(\n",
        "#     st.session_state.table_df.copy(),  # avoid inplace side-effects\n",
        "#     num_rows=\"dynamic\",\n",
        "#     use_container_width=True,\n",
        "#     hide_index=True,\n",
        "#     key=\"features_editor\"\n",
        "# )\n",
        "\n",
        "# # ---------- Controls ----------\n",
        "# run_btn = st.button(\"Prediction\", use_container_width=True, type=\"primary\")\n",
        "\n",
        "# def build_payload_from_table() -> Dict[str, Any]:\n",
        "#     feats = features_dict_from_df(st.session_state.table_df)\n",
        "#     return {\n",
        "#         \"frame\": int(st.session_state.frame),\n",
        "#         \"timestamp\": st.session_state.timestamp,\n",
        "#         \"features\": feats,\n",
        "#         \"decision_threshold\": float(st.session_state.decision_threshold),\n",
        "#     }\n",
        "\n",
        "# st.divider()\n",
        "\n",
        "# # ---------- Action ----------\n",
        "# if run_btn:\n",
        "#     try:\n",
        "#         payload = build_payload_from_table()\n",
        "#         with st.spinner(\"Contacting Lambda...\"):\n",
        "#             start = time.time()\n",
        "#             resp = call_lambda(lambda_url, payload, timeout_s=25.0)\n",
        "#             elapsed = time.time() - start\n",
        "\n",
        "#         st.success(f\"Request OK ({elapsed:.2f}s)\")\n",
        "\n",
        "#         # ----- Colored result summary -----\n",
        "#         pred = resp.get(\"prediction\", {}) or {}\n",
        "#         label = str(pred.get(\"label\", \"—\"))\n",
        "#         prob = pred.get(\"fire_probability\", None)\n",
        "#         lbl_lower = label.lower()\n",
        "\n",
        "#         # Green for Not Fire, Red for Fire\n",
        "#         if \"fire\" in lbl_lower and \"not\" not in lbl_lower:\n",
        "#             colored_box(f\"🔥 Prediction: <b>{label}</b>\", bg=\"#fde8e8\", border=\"#f5c2c2\", color=\"#7a1111\")\n",
        "#         else:\n",
        "#             colored_box(f\"✅ Prediction: <b>{label}</b>\", bg=\"#e6f4ea\", border=\"#b7e1c1\", color=\"#0b5b25\")\n",
        "\n",
        "#         top_cols = st.columns(3)\n",
        "#         with top_cols[0]:\n",
        "#             st.metric(\"Label\", label)\n",
        "#         with top_cols[1]:\n",
        "#             if isinstance(prob, (int, float)):\n",
        "#                 st.metric(\"Fire probability\", f\"{prob:.6f}\")\n",
        "#             else:\n",
        "#                 st.metric(\"Fire probability\", str(prob))\n",
        "#         with top_cols[2]:\n",
        "#             st.metric(\"Frame\", resp.get(\"frame\", payload.get(\"frame\", \"—\")))\n",
        "#         st.caption(f\"Timestamp: {resp.get('timestamp', payload.get('timestamp','—'))}\")\n",
        "\n",
        "#         # ----- Explanation tables (Local first, then Global) -----\n",
        "#         expl = resp.get(\"explanation\", {}) or {}\n",
        "#         lcontrib = expl.get(\"local_contributions\", [])\n",
        "#         gtf = expl.get(\"global_top_features\", [])\n",
        "\n",
        "#         if isinstance(lcontrib, list) and lcontrib:\n",
        "#             st.subheader(\"Local Contributions\")\n",
        "#             st.dataframe(pd.DataFrame(lcontrib), use_container_width=True)\n",
        "\n",
        "#         if isinstance(gtf, list) and gtf:\n",
        "#             st.subheader(\"Global Top Features\")\n",
        "#             st.dataframe(pd.DataFrame(gtf), use_container_width=True)\n",
        "\n",
        "#         # Notes (yellow box)\n",
        "#         notes = expl.get(\"notes\")\n",
        "#         if notes:\n",
        "#             colored_box(f\"📝 {notes}\", bg=\"#fff8db\", border=\"#f4e7a5\", color=\"#6b5b00\")\n",
        "\n",
        "#     except requests.HTTPError as http_err:\n",
        "#         st.error(f\"HTTP error: {http_err}\\nResponse text: {getattr(http_err, 'response', None) and http_err.response.text}\")\n",
        "#     except Exception as e:\n",
        "#         st.error(f\"Error: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}